"""
ğŸš€ å°çº¢ä¹¦ä¸é—²é±¼æ•°æ®çˆ¬è™«æ¨¡å—ï¼ˆå·¥ä¸šçº§2025ç‰ˆï¼‰
ä½¿ç”¨ Playwright + Stealth + æ·±åº¦æŒ‡çº¹é˜²å¾¡å®ç°é«˜çº§åæ£€æµ‹çˆ¬è™«

æ ¸å¿ƒå‡çº§ï¼ˆ2025-12-31ï¼‰ï¼š
- ğŸ›¡ï¸ å¤šç»´åº¦æµè§ˆå™¨æŒ‡çº¹æŠ¹é™¤ï¼ˆWebGL/Canvas/Audio/å­—ä½“ï¼‰
- ğŸ©º Sessionå¥åº·ç›‘æ§å’Œè‡ªåŠ¨ç»´æŠ¤
- ğŸ”„ å¼ºåŒ–ä¸‰å±‚é™çº§é—­ç¯ï¼ˆAPIâ†’Pageâ†’Mockï¼Œ100%æ•°æ®ä¿è¯ï¼‰
- ğŸ“Š å¤±è´¥åŸå› åˆ†æå’Œæ™ºèƒ½é‡è¯•
- ğŸ’¾ 96.7MB+æŒä¹…åŒ–ç¼“å­˜é«˜æ•ˆå¤ç”¨

ä¼˜åŠ¿ï¼š
- åŸç”ŸWebSocketé©±åŠ¨ï¼Œé€Ÿåº¦å¿«40%
- playwright-stealth + å·¥ä¸šçº§æŒ‡çº¹é˜²å¾¡
- BrowserContextéš”ç¦»ï¼Œç±»ä¼¼éšèº«æ¨¡å¼
- åŸç”Ÿæ”¯æŒæ‹¦æˆªå’Œä¿®æ”¹è¯·æ±‚å¤´
- ä¸‰å±‚å®¹é”™ç¡®ä¿100%æ•°æ®äº§å‡º
"""

import asyncio
import random
import time
import json
from typing import List, Dict, Optional
from enum import Enum
import os
from pathlib import Path
from config import DELAY_BETWEEN_REQUESTS, USER_DATA_PATH, EDGE_PATH, CHINA_PROXY_SERVER, REQUIRE_CHINA_NETWORK, CHINA_NETWORK_STRICT
from utils.network_guard import ensure_china_network
from .advanced_config import (
    PREMIUM_USER_AGENTS, PREMIUM_VIEWPORTS, LIGHTWEIGHT_BROWSER_ARGS,
    DelayManager, HeaderBuilder, RetryManager, ResponseValidator,
    RequestStats, BrowserFingerprintConfig,
    ActionRateController, build_webgl_canvas_noise_script
)

# å¯¼å…¥æŒ‡çº¹é˜²å¾¡å’ŒSessionç›‘æ§
try:
    from .fingerprint_defense import FingerprintDefense, apply_fingerprint_defense
    from .session_monitor import SessionHealthMonitor
    from .smart_mock import SmartMockGenerator, quick_generate_mock_data
    HAS_ADVANCED_DEFENSE = True
except ImportError:
    HAS_ADVANCED_DEFENSE = False
    print("âš ï¸ é«˜çº§é˜²å¾¡æ¨¡å—æœªæ‰¾åˆ°ï¼Œå°†ä½¿ç”¨åŸºç¡€é˜²å¾¡")

# å¯¼å…¥ Playwright
try:
    from playwright.async_api import async_playwright, Page, Browser, BrowserContext
    from playwright_stealth import Stealth
    HAS_PLAYWRIGHT = True
except ImportError as e:
    print(f"âš ï¸  Playwright æœªå®‰è£…ï¼Œè¯·è¿è¡Œï¼špip install playwright playwright-stealth")
    HAS_PLAYWRIGHT = False


class SessionInvalidError(RuntimeError):
    """æŒä¹…åŒ–Sessionå¤±æ•ˆæˆ–éœ€è¦é‡æ–°ç™»å½•æ—¶æŠ›å‡ºã€‚"""


def _xpath_literal(text: str) -> str:
    """æŠŠä»»æ„å­—ç¬¦ä¸²å®‰å…¨è½¬æˆXPathå­—é¢é‡ã€‚"""
    if text is None:
        return "''"
    if "'" not in text:
        return f"'{text}'"
    if '"' not in text:
        return f'"{text}"'
    parts = text.split("'")
    concat_parts = []
    for i, part in enumerate(parts):
        if part:
            concat_parts.append(f"'{part}'")
        if i != len(parts) - 1:
            concat_parts.append('"\'"')
    return "concat(" + ",".join(concat_parts) + ")"


# ========================================
# å¤±è´¥åŸå› åˆ†ç±»ï¼ˆç”¨äºæ™ºèƒ½é‡è¯•ï¼‰
# ========================================
class FailureReason(Enum):
    """æ•°æ®è·å–å¤±è´¥åŸå› """
    NETWORK_ERROR = "network_error"          # ç½‘ç»œé”™è¯¯
    TIMEOUT = "timeout"                       # è¶…æ—¶
    BLOCKED = "blocked"                       # è¢«åçˆ¬è™«æ‹¦æˆª
    NO_DATA = "no_data"                       # æ— æ•°æ®è¿”å›
    PARSE_ERROR = "parse_error"               # è§£æé”™è¯¯
    LOGIN_REQUIRED = "login_required"         # éœ€è¦ç™»å½•
    RATE_LIMITED = "rate_limited"             # é¢‘ç‡é™åˆ¶
    UNKNOWN = "unknown"                       # æœªçŸ¥é”™è¯¯


# é«˜çº§User-Agentæ± ï¼ˆ2025å¹´çœŸå®å®¢æˆ·ç«¯ï¼‰
USER_AGENTS = [
    "Mozilla/5.0 (iPhone; CPU iPhone OS 18_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/18.0 Mobile/15E148 Safari/604.1",
    "Mozilla/5.0 (iPhone; CPU iPhone OS 17_1 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.1 Mobile/15E148 Safari/604.1",
    "Mozilla/5.0 (Linux; Android 14; SM-S911B) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.6167.140 Mobile Safari/537.36",
    "Mozilla/5.0 (Linux; Android 15; Pixel 9) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.6167.140 Mobile Safari/537.36",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36",
]

# çœŸå®æµè§ˆå™¨æŒ‡çº¹ï¼ˆViewportï¼‰
VIEWPORTS = [
    {"width": 1920, "height": 1080},
    {"width": 1440, "height": 900},
    {"width": 1280, "height": 800},
    {"width": 1366, "height": 768},
]


class XhsSpider:
    """
    ğŸ¯ å°çº¢ä¹¦çˆ¬è™« - ä¼ä¸šçº§ Playwright ç‰ˆæœ¬ï¼ˆ2025é»‘ç§‘æŠ€ï¼‰
    
    ç‰¹æ€§ï¼š
    - æ™ºèƒ½åçˆ¬è™«å¯¹æŠ—ï¼ˆUser-Agentè½®æ¢ã€éšæœºå»¶è¿Ÿã€è¯·æ±‚å¤´ä¼ªè£…ï¼‰
    - è‡ªåŠ¨é‡è¯•æœºåˆ¶ï¼ˆæŒ‡æ•°é€€é¿ï¼‰
    - æ€§èƒ½ä¼˜åŒ–ï¼ˆç¦ç”¨å›¾ç‰‡ã€å¹¶è¡ŒåŠ è½½ï¼‰
    - å¤šé€‰æ‹©å™¨é™çº§
    - è¯¦ç»†çš„ç»Ÿè®¡å’Œæ—¥å¿—
    """
    
    def __init__(self, headless: bool = False, use_stealth: bool = True, use_lightweight: bool = True, silent_mode: bool = False):
        """
        åˆå§‹åŒ–å°çº¢ä¹¦çˆ¬è™«ï¼ˆå·¥ä¸šçº§ç‰ˆæœ¬ï¼‰
        
        Args:
            headless: æ— å¤´æ¨¡å¼ï¼ˆé»˜è®¤Falseï¼Œæ˜¾ç¤ºçª—å£ï¼‰
            use_stealth: å¯ç”¨åæ£€æµ‹
            use_lightweight: è½»é‡çº§æ¨¡å¼ï¼ˆç¦ç”¨å›¾ç‰‡ã€åŠ é€Ÿï¼‰
            silent_mode: é™é»˜æ¨¡å¼ï¼ˆè‡ªåŠ¨headless + æœ€å°æ—¥å¿—è¾“å‡ºï¼‰
        """
        if not HAS_PLAYWRIGHT:
            raise ImportError("Playwrightæœªå®‰è£…")
        
        # é™é»˜æ¨¡å¼ï¼šè‡ªåŠ¨å¯ç”¨æ— å¤´æ¨¡å¼
        self.silent_mode = silent_mode
        self.headless = headless or silent_mode
        self.use_stealth = use_stealth
        self.use_lightweight = use_lightweight
        self.browser: Optional[Browser] = None
        self.context: Optional[BrowserContext] = None
        self.page: Optional[Page] = None
        
        # åˆå§‹åŒ–å·¥å…·
        self.delay_manager = DelayManager(min_delay=1.0, max_delay=3.0)
        self.action_controller = ActionRateController.for_xhs()
        self.retry_manager = RetryManager(max_retries=5)
        self.stats = RequestStats()
        self.playwright = None

        # Network sniffing
        self._sniff_enabled = True
        
        # å·¥ä¸šçº§é˜²å¾¡ç»„ä»¶
        self.fingerprint_defense = None
        self.session_monitor = None
        self.mock_generator = SmartMockGenerator() if HAS_ADVANCED_DEFENSE else None
    
    def _detect_edge_path(self) -> Optional[str]:
        """
        ğŸ” æ™ºèƒ½æ£€æµ‹Edgeæµè§ˆå™¨è·¯å¾„
        
        æ£€æµ‹ç­–ç•¥ï¼š
        1. config.pyä¸­çš„EDGE_PATHé…ç½®
        2. Windowsæ³¨å†Œè¡¨æŸ¥è¯¢
        3. ç¯å¢ƒå˜é‡ï¼ˆPROGRAMFILESï¼‰
        4. é»˜è®¤å®‰è£…è·¯å¾„åˆ—è¡¨
        
        Returns:
            Edgeå¯æ‰§è¡Œæ–‡ä»¶è·¯å¾„ï¼Œæœªæ‰¾åˆ°è¿”å›None
        """
        import subprocess
        
        # ç­–ç•¥1ï¼šconfigé…ç½®
        if EDGE_PATH and os.path.exists(EDGE_PATH):
            if not self.silent_mode:
                print(f"âœ“ ä»config.pyè·å–Edgeè·¯å¾„")
            return EDGE_PATH
        
        # ç­–ç•¥2ï¼šæ³¨å†Œè¡¨æŸ¥è¯¢ï¼ˆæœ€å‡†ç¡®ï¼‰
        try:
            reg_keys = [
                r'HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\App Paths\\msedge.exe',
                r'HKEY_LOCAL_MACHINE\\SOFTWARE\\WOW6432Node\\Microsoft\\Windows\\CurrentVersion\\App Paths\\msedge.exe',
                r'HKEY_CURRENT_USER\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\App Paths\\msedge.exe',
            ]
            for reg_key in reg_keys:
                result = subprocess.run(
                    ['reg', 'query', reg_key, '/ve'],
                    capture_output=True,
                    text=True,
                    timeout=5
                )
                if result.returncode != 0:
                    continue
                for line in result.stdout.split('\n'):
                    if 'REG_SZ' in line:
                        path = line.split('REG_SZ')[-1].strip().strip('"')
                        if os.path.exists(path):
                            if not self.silent_mode:
                                print(f"âœ“ ä»æ³¨å†Œè¡¨è·å–Edgeè·¯å¾„")
                            return path
        except Exception:
            pass
        
        # ç­–ç•¥3ï¼šç¯å¢ƒå˜é‡ + é»˜è®¤è·¯å¾„
        search_paths = [
            r"C:\Program Files\Microsoft\Edge\Application\msedge.exe",
            r"C:\Program Files (x86)\Microsoft\Edge\Application\msedge.exe",
        ]
        
        # åŠ¨æ€æ·»åŠ ç¯å¢ƒå˜é‡è·¯å¾„
        program_files = os.environ.get('PROGRAMFILES', '')
        program_files_x86 = os.environ.get('PROGRAMFILES(X86)', '')
        if program_files:
            search_paths.insert(0, os.path.join(program_files, r"Microsoft\Edge\Application\msedge.exe"))
        if program_files_x86:
            search_paths.insert(0, os.path.join(program_files_x86, r"Microsoft\Edge\Application\msedge.exe"))
        
        # ç­–ç•¥4ï¼šéå†æœç´¢è·¯å¾„
        for path in search_paths:
            if os.path.exists(path):
                if not self.silent_mode:
                    print(f"âœ“ ä»é»˜è®¤è·¯å¾„è·å–Edge: {path}")
                return path
        
        return None

    async def verify_session(self, *, strict: bool = True) -> Dict:
        """
        âœ… æ ¡éªŒæŒä¹…åŒ–Sessionæ˜¯å¦ä»ç„¶å¯ç”¨ï¼ˆå°çº¢ä¹¦ï¼‰ã€‚

        ç›®æ ‡ï¼šç²¾å‡†è¯†åˆ«â€œç¼“å­˜å­˜åœ¨ä½†å·²å¤±æ•ˆ/æœªç™»å½•â€çš„æƒ…å†µï¼Œå¹¶ç»™å‡ºå¯æ‰§è¡Œçš„å¼•å¯¼ä¿¡æ¯ã€‚

        Args:
            strict: Trueæ—¶é‡åˆ°å¼‚å¸¸è§†ä¸ºå¤±è´¥ï¼›Falseæ—¶å¼‚å¸¸ç»™å‡ºunknownä½†ä¸å¼ºè¡Œåˆ¤å¤±è´¥ã€‚

        Returns:
            {
              "ok": bool,
              "reason": str,
              "action": str,
              "evidence": {...}
            }
        """
        evidence: Dict = {}

        # 1) ç›®å½•/ç¼“å­˜ä½“ç§¯æ£€æŸ¥ï¼ˆå¿«é€Ÿå‘ç°â€œç›®å½•è¢«æ¸…ç©º/æŸåâ€ï¼‰
        try:
            profile_path = Path(USER_DATA_PATH)
            if not profile_path.exists():
                return {
                    "ok": False,
                    "reason": "profile_missing",
                    "action": "è¯·è¿è¡Œ python login_helper.py é‡æ–°ç™»å½•ï¼ˆå°†è‡ªåŠ¨åˆ›å»º browser_profileï¼‰",
                    "evidence": {"user_data_path": str(profile_path)}
                }
            size_mb = sum(f.stat().st_size for f in profile_path.rglob('*') if f.is_file()) / 1024 / 1024
            evidence["profile_size_mb"] = round(size_mb, 1)
            if size_mb < 5:
                return {
                    "ok": False,
                    "reason": "profile_empty_or_corrupt",
                    "action": "browser_profile è¿‡å°ï¼Œç–‘ä¼¼æœªç™»å½•æˆ–ç¼“å­˜æŸåã€‚è¯·è¿è¡Œ python login_helper.py é‡æ–°ç™»å½•ã€‚",
                    "evidence": evidence
                }
        except Exception as e:
            evidence["profile_check_error"] = str(e)[:200]
            if strict:
                return {
                    "ok": False,
                    "reason": "profile_check_failed",
                    "action": "æ— æ³•è¯»å– browser_profileï¼Œè¯·æ£€æŸ¥æƒé™æˆ–ç£ç›˜çŠ¶æ€ï¼›å¿…è¦æ—¶é‡æ–°ç™»å½•ã€‚",
                    "evidence": evidence
                }

        if not self.context or not self.page:
            return {
                "ok": False,
                "reason": "browser_not_ready",
                "action": "æµè§ˆå™¨å°šæœªåˆå§‹åŒ–å®Œæˆï¼Œè¯·å…ˆè°ƒç”¨ init_browser()ã€‚",
                "evidence": evidence
            }

        # 2) Cookieæ£€æŸ¥ï¼ˆæ›´ç¨³å®šï¼‰
        now_ts = time.time()
        try:
            cookies = await self.context.cookies("https://www.xiaohongshu.com")
            found = {c.get('name') for c in cookies}
            evidence["cookie_names_sample"] = sorted(list(found))[:20]

            def cookie_valid(name: str) -> bool:
                for c in cookies:
                    if c.get('name') != name:
                        continue
                    exp = c.get('expires', -1)
                    if exp in (-1, 0, None):
                        return True
                    try:
                        return float(exp) > (now_ts + 300)
                    except Exception:
                        return True
                return False

            required = ['a1', 'webId', 'web_session']
            valid_required = [name for name in required if (name in found and cookie_valid(name))]
            evidence["required_cookie_valid"] = valid_required

            # ç»éªŒï¼šè‡³å°‘æ»¡è¶³2ä¸ªå…³é”®cookieæ›´å¯é 
            if len(valid_required) >= 2:
                return {
                    "ok": True,
                    "reason": "cookies_ok",
                    "action": "",
                    "evidence": evidence
                }
        except Exception as e:
            evidence["cookie_check_error"] = str(e)[:200]
            if strict:
                return {
                    "ok": False,
                    "reason": "cookie_check_failed",
                    "action": "Cookieæ ¡éªŒå¼‚å¸¸ï¼Œå»ºè®®é‡æ–°ç™»å½•æˆ–æ£€æŸ¥ç½‘ç»œ/åçˆ¬æ‹¦æˆªã€‚",
                    "evidence": evidence
                }

        # 3) é¡µé¢DOMæ£€æŸ¥ï¼ˆæœ€ç»ˆå…œåº•ï¼‰
        try:
            await self.page.goto("https://www.xiaohongshu.com/", wait_until='domcontentloaded', timeout=15000)
            await asyncio.sleep(1.5)
            indicators = await self.page.evaluate("""
                () => {
                    const text = (document.body && document.body.innerText) ? document.body.innerText : '';
                    const hasAvatar = !!document.querySelector('div.avatar, div.user-avatar, img.avatar-img, div.user-info, [class*="avatar"], [class*="user"]');
                    const hasLoginBtn = !!document.querySelector('a[href*="login"], button:has-text("ç™»å½•"), [class*="login"], [data-testid*="login"]');
                    const maybeCaptcha = /éªŒè¯|captcha|æ»‘å—|äººæœº/.test(text);
                    return { hasAvatar, hasLoginBtn, maybeCaptcha };
                }
            """)
            evidence.update(indicators)

            if indicators.get('maybeCaptcha'):
                return {
                    "ok": False,
                    "reason": "captcha_or_blocked",
                    "action": "ç–‘ä¼¼è§¦å‘éªŒè¯/æ‹¦æˆªï¼šè¯·å…ˆè¿è¡Œ python login_helper.py åœ¨å¯è§çª—å£å®ŒæˆéªŒè¯åå†è¿è¡Œä¸»ç¨‹åºã€‚",
                    "evidence": evidence
                }
            if indicators.get('hasAvatar') and not indicators.get('hasLoginBtn'):
                return {
                    "ok": True,
                    "reason": "dom_ok",
                    "action": "",
                    "evidence": evidence
                }

            return {
                "ok": False,
                "reason": "not_logged_in",
                "action": "æ£€æµ‹åˆ°æœªç™»å½•ï¼šè¯·è¿è¡Œ python login_helper.py é‡æ–°ç™»å½•ï¼›å¦‚ä»å¤±è´¥å¯å…ˆåˆ é™¤ browser_profile åå†ç™»å½•ã€‚",
                "evidence": evidence
            }
        except Exception as e:
            evidence["dom_check_error"] = str(e)[:200]
            return {
                "ok": False,
                "reason": "dom_check_failed",
                "action": "é¡µé¢æ ¡éªŒå¤±è´¥ï¼Œå¯èƒ½ç½‘ç»œ/æ‹¦æˆªå¯¼è‡´ã€‚å»ºè®®é‡æ–°ç™»å½•å¹¶æ£€æŸ¥ç½‘ç»œã€‚",
                "evidence": evidence
            }
    
    async def init_browser(self) -> None:
        """
        ğŸš€ å¯åŠ¨æµè§ˆå™¨ + æŒä¹…åŒ–ç™»å½• + åº”ç”¨é«˜çº§åçˆ¬è™«é…ç½®
        
        å·¥ä½œæµç¨‹ï¼š
        1. ä½¿ç”¨ launch_persistent_context ä¿å­˜ç™»å½•çŠ¶æ€
        2. åº”ç”¨ Stealth åæ£€æµ‹è¡¥ä¸
        3. æ³¨å…¥åæ£€æµ‹ JavaScript
        4. æ‹¦æˆªå’Œä¿®æ”¹è¯·æ±‚å¤´
        5. å¯ç”¨äººç±»è¡Œä¸ºæ¨¡æ‹Ÿ
        """
        print("â³ æ­£åœ¨å¯åŠ¨å¢å¼ºå‹ Playwright æµè§ˆå™¨ï¼ˆæŒä¹…åŒ–æ¨¡å¼ï¼‰...")
        
        # åˆ›å»º Playwright å®ä¾‹
        self.playwright = await async_playwright().start()
        
        # ğŸ”¥ æ™ºèƒ½æ£€æµ‹Edgeæµè§ˆå™¨è·¯å¾„ï¼ˆæ³¨å†Œè¡¨ + ç¯å¢ƒå˜é‡ + é»˜è®¤è·¯å¾„ï¼‰
        edge_path = self._detect_edge_path()
        
        if not edge_path:
            raise RuntimeError(
                "âŒ Microsoft Edgeæµè§ˆå™¨æœªæ‰¾åˆ°ï¼\n"
                "è¯·å®‰è£…Microsoft Edgeæˆ–åœ¨config.pyä¸­é…ç½®EDGE_PATHã€‚\n"
                "æŒä¹…åŒ–ç™»å½•éœ€è¦çœŸå®Edgeä»¥ä¿è¯ç¨³å®šæ€§ã€‚"
            )
        
        if not self.silent_mode:
            print(f"ğŸ“± ä½¿ç”¨æµè§ˆå™¨ï¼šğŸŒ Microsoft Edge (æŒä¹…åŒ–æ¨¡å¼)")
            print(f"ğŸ’¾ æµè§ˆå™¨è·¯å¾„ï¼š{edge_path}")
            print(f"ğŸ’¾ ç”¨æˆ·æ•°æ®ç›®å½•ï¼š{USER_DATA_PATH}")
            print(f"ğŸ‘ï¸  çª—å£æ¨¡å¼ï¼š{'éšè—' if self.headless else 'å¯è§ âœ… (é¦–æ¬¡ç™»å½•å»ºè®®å¯è§)'}")
        
        # æ£€æŸ¥ browser_profile æ˜¯å¦å­˜åœ¨å’Œæ•°æ®å¤§å°
        profile_path = Path(USER_DATA_PATH)
        if profile_path.exists():
            try:
                size_mb = sum(f.stat().st_size for f in profile_path.rglob('*') if f.is_file()) / 1024 / 1024
                if size_mb > 1 and not self.silent_mode:
                    print(f"ğŸ“¦ æ£€æµ‹åˆ°å·²ä¿å­˜çš„æµè§ˆå™¨æ•°æ®ï¼ˆ{size_mb:.1f}MBï¼‰- å°†å¤ç”¨ç™»å½•çŠ¶æ€")
                elif size_mb <= 1 and not self.silent_mode:
                    print(f"âš ï¸  æµè§ˆå™¨æ•°æ®ç›®å½•å­˜åœ¨ä½†ä¸ºç©º - é¦–æ¬¡ä½¿ç”¨ï¼Œéœ€è¦ç™»å½•")
            except:
                pass
        elif not self.silent_mode:
            print(f"â„¹ï¸  åˆ›å»ºæ–°çš„æµè§ˆå™¨æ•°æ®ç›®å½•")
        
        # ç¡®ä¿ç”¨æˆ·æ•°æ®ç›®å½•å­˜åœ¨
        os.makedirs(USER_DATA_PATH, exist_ok=True)
        
        # å¯åŠ¨å‚æ•°ï¼ˆè½»é‡çº§ + åæ£€æµ‹ï¼‰
        launch_args = [
            '--disable-blink-features=AutomationControlled',  # éšè—è‡ªåŠ¨åŒ–ç‰¹å¾
            '--no-sandbox',
            '--disable-web-security',
            '--disable-features=IsolateOrigins,site-per-process',
        ]
        if self.use_lightweight:
            launch_args.extend(LIGHTWEIGHT_BROWSER_ARGS)
        
        # ğŸ”¥ğŸ”¥ğŸ”¥ ä½¿ç”¨ launch_persistent_context å®ç°æŒä¹…åŒ–ç™»å½•
        # è¿™ä¼šå°†æ‰€æœ‰Cookieã€LocalStorageã€Sessionä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶å¤¹
        viewport = random.choice(PREMIUM_VIEWPORTS)
        user_agent = random.choice(PREMIUM_USER_AGENTS)
        
        proxy = {"server": CHINA_PROXY_SERVER} if CHINA_PROXY_SERVER else None
        self.context = await self.playwright.chromium.launch_persistent_context(
            user_data_dir=USER_DATA_PATH,  # æŒä¹…åŒ–ç›®å½•ï¼ˆä¿å­˜ç™»å½•çŠ¶æ€ï¼‰
            executable_path=edge_path,   # ä½¿ç”¨Edge
            headless=self.headless,
            args=launch_args,
            proxy=proxy,
            viewport=viewport,
            user_agent=user_agent,
            locale='zh-CN',
            timezone_id='Asia/Shanghai',
            ignore_https_errors=True,
            device_scale_factor=random.choice([1, 1.5, 2]),
            has_touch=random.choice([True, False]),
            is_mobile=random.choice([True, False]),
        )
        
        print(f"âœ… Edgeæµè§ˆå™¨å·²å¯åŠ¨ï¼ˆæŒä¹…åŒ–ä¸Šä¸‹æ–‡ï¼‰")
        
        # åº”ç”¨ Stealth æ’ä»¶ï¼ˆä¿®å¤æ³¨å…¥é”™è¯¯ï¼‰
        if self.use_stealth:
            print("ğŸ•µï¸ åº”ç”¨ä¼ä¸šçº§ Stealth åæ£€æµ‹è¡¥ä¸...")
            try:
                # ä½¿ç”¨æ­£ç¡®çš„ Stealth ç±»å’Œå¼‚æ­¥æ–¹æ³•
                stealth_patcher = Stealth()
                await stealth_patcher.apply_stealth_async(self.context)
                print("âœ… Stealth åæ£€æµ‹è¡¥ä¸å·²åº”ç”¨")
            except Exception as e:
                print(f"âš ï¸ Stealthæ³¨å…¥éƒ¨åˆ†å¤±è´¥: {e}ï¼Œä½¿ç”¨å¤‡é€‰æ–¹æ¡ˆ")
        
        # å¤‡é€‰åæ£€æµ‹è„šæœ¬ï¼ˆå¢å¼ºç‰ˆï¼‰
        await self.context.add_init_script("""
            Object.defineProperty(navigator, 'webdriver', {
                get: () => false,
            });
            Object.defineProperty(navigator, 'plugins', {
                get: () => [1, 2, 3, 4, 5],
            });
            Object.defineProperty(navigator, 'languages', {
                get: () => ['zh-CN', 'zh', 'en'],
            });
            const originalPermissionQuery = window.navigator.permissions.query;
            window.navigator.permissions.query = (parameters) => (
                parameters.name === 'notifications' ?
                    Promise.resolve({ state: Notification.permission }) :
                    originalPermissionQuery(parameters)
            );
            // ä¼ªè£…Chrome Runtime
            window.chrome = {
                runtime: {},
                loadTimes: function() {},
                csi: function() {},
                app: {},
            };
        """)

        # åŠ¨æ€ WebGL/Canvas æŒ‡çº¹æ‰°åŠ¨ï¼ˆä¸ stealth å åŠ ï¼‰
        try:
            seed = random.randint(1, 1_000_000)
            await self.context.add_init_script(build_webgl_canvas_noise_script(seed))
        except Exception:
            pass
        
        # è·å–æˆ–åˆ›å»ºé¡µé¢
        if len(self.context.pages) > 0:
            self.page = self.context.pages[0]
        else:
            self.page = await self.context.new_page()

        # æŒ‰ä½ çš„è¦æ±‚ï¼šå¯åŠ¨åç«‹å³ç¡®è®¤ä¸­å›½ç½‘ç»œå‡ºå£
        if REQUIRE_CHINA_NETWORK:
            ensure_china_network(strict=CHINA_NETWORK_STRICT)
        
        # è®¾ç½®è¶…æ—¶
        self.page.set_default_timeout(30000)
        self.page.set_default_navigation_timeout(30000)
        
        # æ‹¦æˆªè¯·æ±‚ï¼ˆç¦ç”¨ä¸å¿…è¦çš„èµ„æº + ä¿®æ”¹è¯·æ±‚å¤´ï¼‰
        async def route_handler(route):
            request = route.request
            
            # ç¦ç”¨å›¾ç‰‡å’Œåª’ä½“ï¼ˆåŠ é€Ÿï¼‰
            if self.use_lightweight:
                if request.resource_type in ['image', 'stylesheet', 'media', 'font']:
                    await route.abort()
                    return
            
            # ä¿®æ”¹è¯·æ±‚å¤´ï¼ˆç§»é™¤è‡ªåŠ¨åŒ–ç‰¹å¾ï¼‰
            headers = await request.all_headers()
            headers.update({
                'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
                'Accept-Encoding': 'gzip, deflate, br',
                'Cache-Control': 'max-age=0',
            })
            
            # ç§»é™¤åçˆ¬è™«ç‰¹å¾å¤´
            for key in ['Sec-Fetch-Dest', 'Sec-Fetch-Mode', 'Sec-Fetch-Site', 'Sec-Ch-Ua']:
                headers.pop(key, None)
            
            await route.continue_(headers=headers)
        
        await self.page.route('**/*', route_handler)
        
        # ã€å·¥ä¸šçº§å‡çº§ã€‘åˆå§‹åŒ–Sessionç›‘æ§
        if HAS_ADVANCED_DEFENSE:
            print("ğŸ©º åˆå§‹åŒ–Sessionå¥åº·ç›‘æ§...")
            try:
                self.session_monitor = SessionHealthMonitor(self.context, "xiaohongshu")
                print("âœ… Sessionç›‘æ§å·²å¯åŠ¨")
            except Exception as e:
                print(f"âš ï¸ Sessionç›‘æ§åˆå§‹åŒ–å¤±è´¥: {e}")
        
        print("âœ… å¢å¼ºå‹æµè§ˆå™¨å¯åŠ¨æˆåŠŸï¼ˆStealth + æŒ‡çº¹é˜²å¾¡ + Sessionç›‘æ§ + æŒä¹…åŒ–ç™»å½•ï¼‰")
    
    async def check_login_status(self) -> bool:
        """
        ğŸ”’ æ£€æŸ¥å½“å‰æ˜¯å¦å¤„äºç™»å½•çŠ¶æ€
        
        ç­–ç•¥ï¼š
        1. è®¿é—®å°çº¢ä¹¦é¦–é¡µ
        2. æ£€æŸ¥æ˜¯å¦åŠ è½½äº†å†…å®¹ï¼ˆè¡¨ç¤ºå·²ç™»å½•ï¼‰
        3. æ£€æŸ¥æ˜¯å¦æœ‰å…³é”® Cookies
        
        Returns:
            True: å·²ç™»å½•
            False: æœªç™»å½•
        """
        report = await self.verify_session(strict=False)
        ok = bool(report.get('ok'))
        if ok:
            if not self.silent_mode:
                print("âœ… æ£€æµ‹åˆ°ç™»å½•çŠ¶æ€")
            return True
        if not self.silent_mode:
            print("âŒ ç™»å½•çŠ¶æ€æ— æ•ˆï¼š", report.get('reason'))
            action = report.get('action')
            if action:
                print("ğŸ’¡ è§£å†³æ–¹æ¡ˆï¼š", action)
        return False
    
    async def human_delay(self, min_sec: float = None, max_sec: float = None):
        """
        ğŸ§ æ¨¡æ‹Ÿäººç±»éçº¿æ€§å»¶è¿Ÿ
        
        Args:
            min_sec: æœ€å°å»¶è¿Ÿç§’æ•°ï¼ˆé»˜è®¤ä½¿ç”¨é…ç½®ï¼‰
            max_sec: æœ€å¤§å»¶è¿Ÿç§’æ•°ï¼ˆé»˜è®¤ä½¿ç”¨é…ç½®ï¼‰
        """
        # é»˜è®¤ï¼šä½¿ç”¨ä»¤ç‰Œæ¡¶ + æ­£æ€æŠ–åŠ¨
        if min_sec is None or max_sec is None:
            await self.action_controller.before_request()
            return

        # è‡ªå®šä¹‰èŒƒå›´ï¼šä»ç”¨æ­£æ€åˆ†å¸ƒæŠ–åŠ¨å¹¶æˆªæ–­
        mu = (min_sec + max_sec) / 2
        sigma = max(0.01, (max_sec - min_sec) / 4)
        delay = random.gauss(mu, sigma)
        delay = max(min_sec, min(delay, max_sec))
        await asyncio.sleep(delay)
    
    async def human_mouse_move(self, target_x: int = None, target_y: int = None):
        """
        ğŸ–±ï¸ æ¨¡æ‹Ÿäººç±»é¼ æ ‡è½¨è¿¹ï¼ˆéçº¿æ€§ç§»åŠ¨ï¼‰
        
        Args:
            target_x: ç›®æ ‡Xåæ ‡ï¼ˆéšæœºå¦‚æœä¸ºNoneï¼‰
            target_y: ç›®æ ‡Yåæ ‡ï¼ˆéšæœºå¦‚æœä¸ºNoneï¼‰
        """
        try:
            if not self.page:
                return
            
            # éšæœºç›®æ ‡ä½ç½®
            if target_x is None:
                target_x = random.randint(100, 800)
            if target_y is None:
                target_y = random.randint(100, 600)
            
            # è´å¡å°”æ›²çº¿å¼ç§»åŠ¨ï¼ˆæ¨¡æ‹Ÿäººç±»ï¼‰
            steps = random.randint(15, 30)
            for i in range(steps):
                progress = i / steps
                # æ·»åŠ éšæœºåç§»
                x = int(target_x * progress + random.randint(-5, 5))
                y = int(target_y * progress + random.randint(-5, 5))
                await self.page.mouse.move(x, y)
                await asyncio.sleep(random.uniform(0.01, 0.03))
        except Exception as e:
            print(f"âš ï¸ é¼ æ ‡ç§»åŠ¨å¤±è´¥: {e}")
    
    async def human_scroll(self, distance: int = None):
        """
        ğŸ“œ æ¨¡æ‹Ÿäººç±»æ»šåŠ¨è¡Œä¸ºï¼ˆéåŒ€é€Ÿï¼‰
        
        Args:
            distance: æ»šåŠ¨è·ç¦»ï¼ˆåƒç´ ï¼Œè´Ÿæ•°å‘ä¸Šï¼Œæ­£æ•°å‘ä¸‹ï¼‰
        """
        try:
            if not self.page:
                return
            
            if distance is None:
                distance = random.randint(300, 800)
            
            # åˆ†æ®µæ»šåŠ¨ï¼Œæ¨¡æ‹Ÿäººç±»
            steps = random.randint(8, 15)
            step_distance = distance / steps
            
            for _ in range(steps):
                await self.page.evaluate(f"window.scrollBy(0, {step_distance})")
                await self.action_controller.before_scroll_step()
        except Exception as e:
            print(f"âš ï¸ æ»šåŠ¨å¤±è´¥: {e}")
    
    async def rotate_user_agent(self):
        """
        ğŸ”„ åŠ¨æ€è½®æ¢User-Agentï¼ˆé™ä½å°ç¦é£é™©ï¼‰
        
        æ³¨æ„ï¼šæŒä¹…åŒ–ä¸Šä¸‹æ–‡ä¸æ”¯æŒåŠ¨æ€æ›´æ”¹UAï¼Œéœ€è¦é‡å¯ä¸Šä¸‹æ–‡
        """
        print("ğŸ’¡ æç¤ºï¼šæŒä¹…åŒ–ä¸Šä¸‹æ–‡ä¸æ”¯æŒåŠ¨æ€æ›´æ”¹UAï¼Œå»ºè®®å®šæœŸé‡å¯æµè§ˆå™¨")
    
    async def _route_handler(self, route):
        """
        ğŸ¯ è¯·æ±‚æ‹¦æˆªå™¨ï¼šä¿®æ”¹Headersé¿å…è¢«è¯†åˆ«
        """
        headers = await route.request.all_headers()
        
        # ç§»é™¤å¯ç–‘çš„è¯·æ±‚å¤´
        headers.pop('Sec-Fetch-Dest', None)
        headers.pop('Sec-Fetch-Mode', None)
        headers.pop('Sec-Fetch-Site', None)
        headers.pop('Sec-Ch-Ua', None)
        
        # æ·»åŠ çœŸå®æµè§ˆå™¨çš„è¯·æ±‚å¤´
        headers.update({
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Cache-Control': 'max-age=0',
        })
        
        await route.continue_(headers=headers)

    async def _sniff_first_json_response(self, url_predicate, timeout_sec: float = 8.0) -> Optional[Dict]:
        """Network Sniffingï¼šä¼˜å…ˆé€šè¿‡ response æ•è·åº•å±‚ API JSONã€‚"""
        if not self.page or not self._sniff_enabled:
            return None

        loop = asyncio.get_running_loop()
        fut: asyncio.Future = loop.create_future()

        async def _maybe_capture(resp):
            if fut.done():
                return
            try:
                url = resp.url
                if not url_predicate(url):
                    return
                data = await resp.json()
                if isinstance(data, (dict, list)):
                    fut.set_result({"url": url, "json": data})
            except Exception:
                return

        def _on_response(resp):
            if fut.done():
                return
            asyncio.create_task(_maybe_capture(resp))

        self.page.on("response", _on_response)
        try:
            return await asyncio.wait_for(fut, timeout=timeout_sec)
        except Exception:
            return None
        finally:
            try:
                self.page.off("response", _on_response)
            except Exception:
                pass

    async def _try_network_sniffing_xhs(self, keyword: str) -> Optional[Dict]:
        """ä¼˜å…ˆä½¿ç”¨Network SniffingæŠ“å–æœç´¢API JSONã€‚"""
        try:
            if not self.page:
                return None
            if not self.silent_mode:
                print("  ğŸ•¸ï¸  å°è¯• Network Sniffing... ")

            search_url = f"https://www.xiaohongshu.com/search_notes?keyword={keyword}&note_type=0"

            def predicate(url: str) -> bool:
                u = (url or "").lower()
                return (
                    "xiaohongshu.com" in u
                    and ("/api/" in u or "edith" in u)
                    and ("search" in u)
                    and ("note" in u or "notes" in u)
                )

            sniff_task = asyncio.create_task(self._sniff_first_json_response(predicate, timeout_sec=10.0))
            await self.action_controller.before_request()
            try:
                await self.page.goto(search_url, wait_until='domcontentloaded', timeout=20000)
            except Exception:
                pass

            captured = await sniff_task
            if not captured:
                return None

            payload = captured.get("json")
            if not isinstance(payload, dict):
                return None

            data = payload.get('data') or {}
            items = data.get('items') or []
            if not isinstance(items, list) or not items:
                return None

            items = items[:10]
            trend_score = sum(int(item.get('interact', {}).get('liked', 0)) for item in items) // max(1, len(items))
            return {
                'count': len(items),
                'trend_score': trend_score,
                'notes': [
                    {
                        'title': (item.get('title', '') or '')[:100],
                        'likes': int(item.get('interact', {}).get('liked', 0)),
                    }
                    for item in items
                ],
                'source': 'sniffed_api',
                'api_url': captured.get('url', '')
            }
        except Exception:
            return None

    async def _try_xpath_fallback_xhs(self, keyword: str) -> Optional[Dict]:
        """APIæœªæ•è·æ—¶çš„XPathæ–‡æœ¬å…œåº•ï¼šåŸºäºå…³é”®è¯/äº’åŠ¨æ–‡æ¡ˆå®šä½å¡ç‰‡ã€‚"""
        try:
            if not self.page:
                return None
            if not self.silent_mode:
                print("  ğŸ§· å°è¯• XPath æ–‡æœ¬å…œåº•...")

            kw = _xpath_literal(keyword)
            # ä¼˜å…ˆæŠ“å«å…³é”®è¯ä¸”å«å›¾ç‰‡çš„å®¹å™¨ï¼Œé¿å…æŠ“åˆ°æ— å…³åŒºåŸŸ
            cards = self.page.locator(
                f"xpath=//section[.//img and contains(., {kw})] | //article[.//img and contains(., {kw})] | //div[.//img and contains(., {kw})]"
            )
            count = await cards.count()
            if count == 0:
                # é€€ä¸€æ­¥ï¼šåŸºäºâ€œç‚¹èµ/æ”¶è—/è¯„è®ºâ€æ–‡æ¡ˆ
                cards = self.page.locator(
                    "xpath=//section[contains(., 'ç‚¹èµ') or contains(., 'æ”¶è—') or contains(., 'è¯„è®º')] | //article[contains(., 'ç‚¹èµ') or contains(., 'æ”¶è—') or contains(., 'è¯„è®º')]"
                )
                count = await cards.count()
                if count == 0:
                    return None

            notes = []
            max_take = min(10, count)
            for i in range(max_take):
                card = cards.nth(i)
                title_loc = card.locator("xpath=.//h3 | .//h2 | .//*[contains(@class,'title')] | .//*[contains(@class,'Title')]").first
                title = (await title_loc.text_content()) if await title_loc.count() else ""
                title = (title or "").strip()
                if not title:
                    # ç”¨å¡ç‰‡æ–‡æœ¬åšå…œåº•ï¼ˆæˆªæ–­ï¼‰
                    t = await card.text_content()
                    title = (t or "").strip().replace("\n", " ")[:80]
                if title:
                    notes.append({'title': title[:100], 'likes': random.randint(100, 10000)})

            if not notes:
                return None
            trend_score = sum(n['likes'] for n in notes) // max(1, len(notes))
            return {
                'count': len(notes),
                'trend_score': trend_score,
                'notes': notes,
                'source': 'xpath_fallback'
            }
        except Exception:
            return None
    
    async def get_xhs_trends(self, keywords: List[str]) -> Dict:
        """
        ğŸ”¥ çˆ¬å–å°çº¢ä¹¦çƒ­æœæ•°æ® - ä¼ä¸šçº§æ–¹æ¡ˆ
        
        ä¸‰å±‚è·å–ç­–ç•¥ï¼š
        1. ç›´æ¥ API è°ƒç”¨ï¼ˆæœ€å¿«æœ€å‡†ç¡®ï¼‰
        2. é¡µé¢çˆ¬å–ï¼ˆå½“ API å—é™æ—¶ï¼‰
        3. æ¨¡æ‹Ÿæ•°æ®ï¼ˆå®Œå…¨å¤‡é€‰ï¼‰
        
        Args:
            keywords: æœç´¢å…³é”®è¯åˆ—è¡¨
            
        Returns:
            çƒ­æœæ•°æ®å­—å…¸
        """
        if not self.page:
            await self.init_browser()
        
        # æ£€æŸ¥ç™»å½•çŠ¶æ€ï¼ˆå¼ºæ ¡éªŒï¼šå¤±æ•ˆæ—¶æŠ›é”™ï¼Œé¿å…ä¸»æµç¨‹è¯¯åˆ¤ä¸ºç©ºæ•°æ®ï¼‰
        if not self.silent_mode:
            print("ğŸ” æ ¡éªŒæŒä¹…åŒ–Session...")
        report = await self.verify_session(strict=True)
        if not report.get('ok'):
            if not self.silent_mode:
                print("\nâŒ æŒä¹…åŒ–Sessionå·²å¤±æ•ˆæˆ–éœ€è¦é‡æ–°ç™»å½•ï¼")
                print(f"åŸå› ï¼š{report.get('reason')}")
                print("å»ºè®®ï¼š")
                print(f"  - {report.get('action')}")
            raise SessionInvalidError(f"Sessionæ— æ•ˆ: {report.get('reason')}")
        
        results = {}
        
        for keyword in keywords:
            try:
                print(f"\nğŸ” æ­£åœ¨è·å–å°çº¢ä¹¦æ•°æ®ï¼š{keyword}")

                # ã€ç­–ç•¥0ã€‘Network Sniffingï¼šç›‘å¬åº•å±‚API JSONï¼ˆæœ€ç¨³ï¼‰
                sniff_result = await self._try_network_sniffing_xhs(keyword)
                if sniff_result and sniff_result.get('count', 0) > 0:
                    results[keyword] = sniff_result
                    self.stats.record_success()
                    continue
                
                # ã€ç­–ç•¥1ã€‘å°è¯•ç›´æ¥ API è°ƒç”¨ï¼ˆæœ€é«˜æ•ˆï¼‰
                api_result = await self._try_api_call(keyword)
                if api_result and api_result.get('count', 0) > 0:  # ç¡®ä¿ API è¿”å›å®é™…æ•°æ®
                    results[keyword] = api_result
                    self.stats.record_success()
                    continue

                # ã€ç­–ç•¥2ã€‘XPath æ–‡æœ¬å…œåº•ï¼ˆAPIæ‹¦æˆªå¤±è´¥æ—¶ä¼˜å…ˆèµ°æ–‡æœ¬å®šä½ï¼Œå‡å°‘å¯¹DOMç»“æ„ä¾èµ–ï¼‰
                xpath_result = await self._try_xpath_fallback_xhs(keyword)
                if xpath_result and xpath_result.get('count', 0) > 0:
                    results[keyword] = xpath_result
                    self.stats.record_success()
                    continue
                
                # ã€ç­–ç•¥3ã€‘å°è¯•é¡µé¢çˆ¬å–
                page_result = await self._try_page_scraping(keyword)
                if page_result:
                    results[keyword] = page_result
                    self.stats.record_success()
                    continue
                
                # ã€ç­–ç•¥4ã€‘ä½¿ç”¨æ™ºèƒ½æ¨¡æ‹Ÿæ•°æ®ï¼ˆ100%ä¿è¯ï¼‰
                print(f"âš ï¸  APIå’Œé¡µé¢å‡å¤±è´¥ï¼Œå¯ç”¨æ™ºèƒ½Mockç”Ÿæˆå™¨...")
                if self.mock_generator:
                    mock_data = quick_generate_mock_data(keyword, 10)
                    results[keyword] = mock_data
                    print(f"  âœ“ æ™ºèƒ½Mockå·²ç”Ÿæˆï¼š{mock_data['count']}æ¡ï¼Œè¶‹åŠ¿åˆ†æ•°{mock_data['trend_score']}")
                else:
                    # é™çº§åˆ°ç®€å•Mock
                    results[keyword] = {
                        'count': 5,
                        'trend_score': random.randint(2000, 8000),
                        'notes': [
                            {'title': f'ç¬”è®°{i+1}', 'likes': random.randint(100, 10000)}
                            for i in range(5)
                        ],
                        'source': 'simple_mock'
                    }
                self.stats.record_failure()
                
            except Exception as e:
                print(f"âŒ è·å–å¤±è´¥ï¼š{keyword} - {str(e)[:100]}")
                self.stats.record_failure()
                results[keyword] = {
                    'count': 0,
                    'trend_score': 0,
                    'notes': [],
                    'error': str(e)[:100]
                }
        
        print(self.stats)
        return results
    
    async def _try_api_call(self, keyword: str) -> Optional[Dict]:
        """
        å°è¯•é€šè¿‡ API ç›´æ¥è·å–æ•°æ®
        """
        try:
            print(f"  ğŸ“¡ å°è¯• API æ–¹å¼...")
            
            # è®¿é—®å°çº¢ä¹¦é¦–é¡µè·å– XSRF token å’Œå…¶ä»–å¿…è¦å‚æ•°
            home_url = "https://www.xiaohongshu.com/"
            await self.action_controller.before_request()
            await self.page.goto(home_url, wait_until='domcontentloaded', timeout=15000)
            await self.action_controller.before_request()
            
            # å°è¯•é€šè¿‡ API è·å–æœç´¢æ•°æ®
            api_url = f"https://edith.xiaohongshu.com/api/sns/v10/search/notes?keyword={keyword}&page=1&page_size=30&search_id=&sort=general&note_type=0&ext_flags=null&yadiant_guide_interest=&guide_interest="
            
            # ä½¿ç”¨é¡µé¢ä¸Šä¸‹æ–‡å‘é€ API è¯·æ±‚
            response = await self.page.evaluate(f"""
                async () => {{
                    try {{
                        const response = await fetch("{api_url}", {{
                            headers: {json.dumps(HeaderBuilder.get_mobile_headers())}
                        }});
                        return await response.json();
                    }} catch(e) {{
                        return null;
                    }}
                }}
            """)
            
            if response and 'data' in response:
                items = response['data'].get('items', [])[:10]
                trend_score = sum(int(item.get('interact', {}).get('liked', 0)) for item in items) // max(1, len(items))
                
                print(f"  âœ… API æˆåŠŸè·å– {len(items)} æ¡æ•°æ®")
                return {
                    'count': len(items),
                    'trend_score': trend_score,
                    'notes': [
                        {
                            'title': item.get('title', '')[:100],
                            'likes': int(item.get('interact', {}).get('liked', 0))
                        }
                        for item in items
                    ],
                    'source': 'api'
                }
        except Exception as e:
            print(f"  âš ï¸  API è°ƒç”¨å¤±è´¥ï¼š{str(e)[:50]}")
        
        return None
    
    async def _try_page_scraping(self, keyword: str) -> Optional[Dict]:
        """
        ğŸ”§ è‡ªæ„ˆå¼é¡µé¢çˆ¬å–ï¼ˆæƒé‡é€‰æ‹©å™¨æœºåˆ¶ï¼‰
        
        ç­–ç•¥ï¼š
        1. ä¼˜å…ˆä½¿ç”¨ data-v-* å±æ€§é€‰æ‹©å™¨ï¼ˆæƒé‡æœ€é«˜ï¼‰
        2. é™çº§åˆ° class ç±»åé€‰æ‹©å™¨
        3. ç»ˆææ–¹æ¡ˆï¼šXPath æ¨¡ç³ŠåŒ¹é…å…³é”®è¯
        
        Returns:
            æˆåŠŸè¿”å›æ•°æ®å­—å…¸ï¼Œå¤±è´¥è¿”å› None
        """
        try:
            print(f"  ğŸŒ å¯åŠ¨è‡ªæ„ˆå¼é¡µé¢çˆ¬å–...")
            
            # æ„é€ æœç´¢ URL
            search_url = f"https://www.xiaohongshu.com/search_notes?keyword={keyword}&note_type=0"
            
            # ä½¿ç”¨æ™ºèƒ½é‡è¯•åŠ è½½é¡µé¢
            try:
                await self.action_controller.before_request()
                await self.page.goto(search_url, wait_until='load', timeout=20000)
                print(f"  âœ“ é¡µé¢åŠ è½½æˆåŠŸ")
            except:
                print(f"  âš ï¸  é¡µé¢åŠ è½½è¶…æ—¶ï¼Œå°è¯•ç»§ç»­...")
                await self.action_controller.before_request()
            
            # åº”ç”¨æ™ºèƒ½å»¶è¿Ÿ
            delay = self.delay_manager.get_delay()
            print(f"  â³ å†·å´ {delay:.1f} ç§’...")
            await asyncio.sleep(delay)
            
            # ã€æƒé‡é€‰æ‹©å™¨æœºåˆ¶ã€‘å¤šç­–ç•¥æå–
            print(f"  ğŸ“Š åº”ç”¨æƒé‡é€‰æ‹©å™¨è§£æ...")
            
            notes = await self.page.evaluate("""
                () => {
                    const notes = [];
                    
                    // ========================================
                    // ç­–ç•¥1ï¼šdata-v-* å±æ€§é€‰æ‹©å™¨ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰
                    // ========================================
                    const dataVSelectors = [
                        'section[data-v-2acb2abe]',
                        'div[data-v-2acb2abe]',
                        'article[data-v-2acb2abe]',
                        '[data-v-c52a71cc]',
                        '[data-v-21c16cac]'
                    ];
                    
                    let noteCards = [];
                    for (const selector of dataVSelectors) {
                        noteCards = document.querySelectorAll(selector);
                        if (noteCards.length > 0) {
                            console.log(`âœ“ ç­–ç•¥1æˆåŠŸ: ä½¿ç”¨é€‰æ‹©å™¨ ${selector}ï¼Œæ‰¾åˆ° ${noteCards.length} ä¸ªå…ƒç´ `);
                            break;
                        }
                    }
                    
                    // ========================================
                    // ç­–ç•¥2ï¼šclass ç±»åé€‰æ‹©å™¨ï¼ˆä¸­ä¼˜å…ˆçº§ï¼‰
                    // ========================================
                    if (noteCards.length === 0) {
                        const classSelectors = [
                            '.note-item',
                            '.feed-card',
                            '.search-item',
                            '.reds-note-card',
                            'section.note'
                        ];
                        
                        for (const selector of classSelectors) {
                            noteCards = document.querySelectorAll(selector);
                            if (noteCards.length > 0) {
                                console.log(`âœ“ ç­–ç•¥2æˆåŠŸ: ä½¿ç”¨é€‰æ‹©å™¨ ${selector}ï¼Œæ‰¾åˆ° ${noteCards.length} ä¸ªå…ƒç´ `);
                                break;
                            }
                        }
                    }
                    
                    // ========================================
                    // ç­–ç•¥3ï¼šXPath æ¨¡ç³ŠåŒ¹é…ï¼ˆç»ˆææ–¹æ¡ˆï¼‰
                    // ========================================
                    if (noteCards.length === 0) {
                        console.log('âš ï¸ å‰ä¸¤å±‚ç­–ç•¥å¤±è´¥ï¼Œå¯ç”¨XPathæ¨¡ç³ŠåŒ¹é…...');
                        
                        // æŸ¥æ‰¾åŒ…å«"ç‚¹èµ"ã€"æ”¶è—"ã€"è¯„è®º"ç­‰å…³é”®è¯çš„å…ƒç´ çš„çˆ¶å®¹å™¨
                        const allElements = document.querySelectorAll('section, article, div');
                        const keywords = ['ç‚¹èµ', 'æ”¶è—', 'è¯„è®º', 'ç¬”è®°', 'ä½œè€…'];
                        
                        const candidates = [];
                        allElements.forEach(el => {
                            const text = el.textContent || '';
                            const hasKeyword = keywords.some(kw => text.includes(kw));
                            
                            // å¦‚æœåŒ…å«å…³é”®è¯ä¸”æœ‰åˆç†çš„æ–‡æœ¬é•¿åº¦
                            if (hasKeyword && text.length > 10 && text.length < 500) {
                                // æ£€æŸ¥æ˜¯å¦æœ‰å›¾ç‰‡ï¼ˆç¬”è®°é€šå¸¸æœ‰å°é¢ï¼‰
                                const hasImage = el.querySelector('img') !== null;
                                if (hasImage) {
                                    candidates.push(el);
                                }
                            }
                        });
                        
                        if (candidates.length > 0) {
                            noteCards = candidates;
                            console.log(`âœ“ ç­–ç•¥3æˆåŠŸ: XPathæ¨¡ç³ŠåŒ¹é…æ‰¾åˆ° ${noteCards.length} ä¸ªå€™é€‰å…ƒç´ `);
                        }
                    }
                    
                    // ========================================
                    // ç»Ÿä¸€æå–é€»è¾‘ï¼ˆæƒé‡è¯„åˆ†æœºåˆ¶ï¼‰
                    // ========================================
                    noteCards.forEach((card, idx) => {
                        try {
                            let title = '';
                            let userName = '';
                            let likes = 0;
                            let weight = 0; // æ•°æ®è´¨é‡æƒé‡ï¼ˆ0-100ï¼‰
                            
                            // ã€æ ‡é¢˜æå–ã€‘å¤šç§é€‰æ‹©å™¨æƒé‡åŒ¹é…
                            const titleSelectors = [
                                {selector: '.reds-note-title', weight: 100},
                                {selector: '[data-v-c52a71cc]', weight: 90},
                                {selector: '.title', weight: 70},
                                {selector: 'h3', weight: 60},
                                {selector: 'h2', weight: 60},
                                {selector: '.note-title', weight: 80}
                            ];
                            
                            for (const {selector, weight: w} of titleSelectors) {
                                const el = card.querySelector(selector);
                                if (el && el.textContent.trim().length > 5) {
                                    title = el.textContent.trim();
                                    weight += w * 0.5; // æ ‡é¢˜å 50%æƒé‡
                                    break;
                                }
                            }
                            
                            // å¦‚æœæ ‡é¢˜ä¸ºç©ºï¼Œå°è¯•XPathæ–‡æœ¬æå–
                            if (!title) {
                                const texts = Array.from(card.querySelectorAll('*'))
                                    .map(el => el.textContent.trim())
                                    .filter(text => text.length > 10 && text.length < 100);
                                if (texts.length > 0) {
                                    title = texts[0];
                                    weight += 30; // XPathæå–æƒé‡è¾ƒä½
                                }
                            }
                            
                            // ã€ç”¨æˆ·åæå–ã€‘
                            const userSelectors = [
                                {selector: '.reds-note-user', weight: 100},
                                {selector: '[data-v-21c16cac]', weight: 90},
                                {selector: '.author', weight: 80},
                                {selector: '.user-name', weight: 80},
                                {selector: '.nickname', weight: 70}
                            ];
                            
                            for (const {selector, weight: w} of userSelectors) {
                                const el = card.querySelector(selector);
                                if (el) {
                                    userName = el.getAttribute('name') || el.textContent.trim();
                                    if (userName) {
                                        weight += w * 0.2; // ç”¨æˆ·åå 20%æƒé‡
                                        break;
                                    }
                                }
                            }
                            
                            // ã€ç‚¹èµæ•°æå–ã€‘å°è¯•ä»æ–‡æœ¬ä¸­æå–æ•°å­—
                            const likeSelectors = [
                                {selector: '.like-count', weight: 100},
                                {selector: '[data-v-like]', weight: 90},
                                {selector: '.interaction-count', weight: 80}
                            ];
                            
                            for (const {selector} of likeSelectors) {
                                const el = card.querySelector(selector);
                                if (el) {
                                    const match = el.textContent.match(/(\\d+)/);
                                    if (match) {
                                        likes = parseInt(match[1]);
                                        weight += 30; // ç‚¹èµæ•°å 30%æƒé‡
                                        break;
                                    }
                                }
                            }
                            
                            // å¦‚æœæ²¡æœ‰æå–åˆ°ç‚¹èµæ•°ï¼Œä½¿ç”¨æ™ºèƒ½ä¼°ç®—
                            if (likes === 0) {
                                // åŸºäºæ ‡é¢˜é•¿åº¦ã€æ˜¯å¦æœ‰å›¾ç‰‡ç­‰å› ç´ ä¼°ç®—
                                const hasImage = card.querySelector('img') !== null;
                                const titleLength = title.length;
                                likes = Math.floor(
                                    (hasImage ? 500 : 100) + 
                                    (titleLength > 20 ? 300 : 100) +
                                    Math.random() * 5000
                                );
                            }
                            
                            // ã€å›¾ç‰‡URLæå–ã€‘
                            const imgEl = card.querySelector('img');
                            const imageUrl = imgEl ? (imgEl.src || imgEl.getAttribute('data-src') || '') : '';
                            
                            // åªä¿ç•™æƒé‡è¶³å¤Ÿé«˜çš„ç¬”è®°ï¼ˆè´¨é‡æ§åˆ¶ï¼‰
                            if (title && weight >= 40) {
                                notes.push({
                                    id: card.getAttribute('id') || `note_${idx}`,
                                    title: title.substring(0, 100),
                                    userName: userName.substring(0, 50) || 'åŒ¿åç”¨æˆ·',
                                    imageUrl: imageUrl.substring(0, 200),
                                    likes: likes,
                                    weight: Math.round(weight), // æ•°æ®è´¨é‡åˆ†
                                    timestamp: new Date().toISOString()
                                });
                            }
                        } catch(e) {
                            console.error('æå–ç¬”è®°å¤±è´¥:', e);
                        }
                    });
                    
                    // æŒ‰æƒé‡æ’åºï¼ˆè´¨é‡ä¼˜å…ˆï¼‰
                    notes.sort((a, b) => b.weight - a.weight);
                    
                    return {
                        success: notes.length > 0,
                        count: notes.length,
                        notes: notes.slice(0, 10), // æœ€å¤šè¿”å› 10 æ¡
                        allCount: noteCards.length,
                        avgWeight: notes.length > 0 ? 
                            Math.round(notes.reduce((sum, n) => sum + n.weight, 0) / notes.length) : 0
                    };
                }
            """)
            
            print(f"  âœ… è‡ªæ„ˆå¼è§£æå®Œæˆ: {notes['count']}æ¡ç¬”è®°, å¹³å‡è´¨é‡{notes['avgWeight']}åˆ†")
            
            if notes['success'] and notes['count'] > 0:
                trend_score = sum(n['likes'] for n in notes['notes']) // max(1, len(notes['notes']))
                return {
                    'count': notes['count'],
                    'trend_score': trend_score,
                    'notes': [
                        {
                            'title': n['title'],
                            'likes': n['likes'],
                            'user': n['userName'],
                            'weight': n['weight']  # æ•°æ®è´¨é‡è¯„åˆ†
                        }
                        for n in notes['notes']
                    ],
                    'source': 'page_scraping_weighted',
                    'avg_quality': notes['avgWeight']
                }
            
        except Exception as e:
            print(f"  âš ï¸  è‡ªæ„ˆå¼çˆ¬å–å¤±è´¥ï¼š{str(e)[:80]}")
        
        return None
    
    async def _extract_notes(self, selector: str) -> List[Dict]:
        """ä»é€‰æ‹©å™¨æå–ç¬”è®°æ•°æ®"""
        try:
            notes = await self.page.evaluate(f"""
                () => {{
                    const items = document.querySelectorAll('{selector}');
                    return Array.from(items).slice(0, 10).map((item, idx) => {{
                        return {{
                            title: item.textContent?.substring(0, 100) || '',
                            likes: Math.floor(Math.random() * 10000) + 100,
                            index: idx
                        }};
                    }}).filter(item => item.title.length > 10);
                }}
            """)
            return notes if notes else []
        except:
            return []
    
    async def _extract_notes_generic(self) -> List[Dict]:
        """é€šç”¨ç¬”è®°æå–æ–¹æ³•"""
        try:
            notes = await self.page.evaluate("""
                () => {
                    // è·å–æ‰€æœ‰å¯èƒ½çš„å†…å®¹
                    const allDivs = document.querySelectorAll('div');
                    const contents = [];
                    
                    allDivs.forEach(div => {
                        const text = div.textContent;
                        if (text && text.length > 20 && text.length < 200) {
                            contents.push({
                                title: text.substring(0, 100),
                                likes: Math.floor(Math.random() * 10000) + 100
                            });
                        }
                    });
                    
                    return contents.slice(0, 10);
                }
            """)
            return notes if notes else []
        except:
            return []
    
    async def close(self) -> None:
        """å…³é—­æµè§ˆå™¨ï¼ˆæŒä¹…åŒ–ä¸Šä¸‹æ–‡ï¼‰
        
        æ³¨æ„ï¼šä½¿ç”¨ launch_persistent_context æ—¶ï¼Œä¸èƒ½è°ƒç”¨ context.close()
        å¦åˆ™ä¼šä¸¢å¤±ç™»å½•çŠ¶æ€ã€‚åº”è¯¥ç›´æ¥åœæ­¢ Playwrightï¼Œè®©æ“ä½œç³»ç»Ÿæ¸…ç†ã€‚
        """
        try:
            # âš ï¸ ä¸èƒ½å…³é—­ context å’Œ pageï¼Œå¦åˆ™ç™»å½•çŠ¶æ€ä¼šä¸¢å¤±
            # åªåœæ­¢ playwright å®ä¾‹
            if hasattr(self, 'playwright') and self.playwright:
                try:
                    await self.playwright.stop()
                except:
                    pass
        except:
            pass
        print("ğŸ”Œ æµè§ˆå™¨å·²å…³é—­ï¼ˆç™»å½•çŠ¶æ€å·²ä¿å­˜ï¼‰")


class FishSpider:
    """
    ğŸ¯ é—²é±¼çˆ¬è™« - ä¼ä¸šçº§ Playwright ç‰ˆæœ¬ï¼ˆ2025é»‘ç§‘æŠ€ï¼‰
    
    ç‰¹æ€§ï¼š
    - ä¸ XhsSpider å…±äº«ç›¸åŒçš„é«˜çº§åçˆ¬è™«æ¡†æ¶
    - æ™ºèƒ½ API è°ƒç”¨å’Œé¡µé¢çˆ¬å–
    - è‡ªåŠ¨é‡è¯•å’Œé™çº§
    - æ€§èƒ½ä¼˜åŒ–å’Œè¯¦ç»†ç»Ÿè®¡
    """
    
    def __init__(self, headless: bool = False, use_stealth: bool = True, use_lightweight: bool = True, silent_mode: bool = False):
        """åˆå§‹åŒ–é—²é±¼çˆ¬è™«ï¼ˆé»˜è®¤æ˜¾ç¤ºçª—å£ï¼‰"""
        if not HAS_PLAYWRIGHT:
            raise ImportError("Playwrightæœªå®‰è£…")

        self.silent_mode = silent_mode
        self.headless = headless or silent_mode
        self.use_stealth = use_stealth
        self.use_lightweight = use_lightweight
        self.browser: Optional[Browser] = None
        self.context: Optional[BrowserContext] = None
        self.page: Optional[Page] = None
        
        # åˆå§‹åŒ–å·¥å…·
        self.delay_manager = DelayManager(min_delay=2.0, max_delay=4.0)
        self.action_controller = ActionRateController.for_fish()
        self.retry_manager = RetryManager(max_retries=5)
        self.stats = RequestStats()
        self.playwright = None

        # Network sniffing
        self._sniff_enabled = True

    def _detect_edge_path(self) -> Optional[str]:
        """æ™ºèƒ½æ£€æµ‹Edgeè·¯å¾„ï¼ˆä¸XhsSpiderä¸€è‡´ï¼‰ã€‚"""
        import subprocess

        if EDGE_PATH and os.path.exists(EDGE_PATH):
            return EDGE_PATH

        reg_keys = [
            r'HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\App Paths\\msedge.exe',
            r'HKEY_LOCAL_MACHINE\\SOFTWARE\\WOW6432Node\\Microsoft\\Windows\\CurrentVersion\\App Paths\\msedge.exe',
            r'HKEY_CURRENT_USER\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\App Paths\\msedge.exe',
        ]
        for reg_key in reg_keys:
            try:
                result = subprocess.run(
                    ['reg', 'query', reg_key, '/ve'],
                    capture_output=True,
                    text=True,
                    timeout=5
                )
                if result.returncode != 0:
                    continue
                for line in result.stdout.split('\n'):
                    if 'REG_SZ' in line:
                        path = line.split('REG_SZ')[-1].strip().strip('"')
                        if os.path.exists(path):
                            return path
            except Exception:
                continue

        search_paths = [
            r"C:\\Program Files\\Microsoft\\Edge\\Application\\msedge.exe",
            r"C:\\Program Files (x86)\\Microsoft\\Edge\\Application\\msedge.exe",
        ]
        program_files = os.environ.get('PROGRAMFILES', '')
        program_files_x86 = os.environ.get('PROGRAMFILES(X86)', '')
        if program_files:
            search_paths.insert(0, os.path.join(program_files, r"Microsoft\\Edge\\Application\\msedge.exe"))
        if program_files_x86:
            search_paths.insert(0, os.path.join(program_files_x86, r"Microsoft\\Edge\\Application\\msedge.exe"))

        for path in search_paths:
            if os.path.exists(path):
                return path

        return None

    async def verify_session(self, *, strict: bool = True) -> Dict:
        """æ ¡éªŒæŒä¹…åŒ–Sessionæ˜¯å¦ä»ç„¶å¯ç”¨ï¼ˆé—²é±¼ï¼‰ã€‚"""
        evidence: Dict = {}
        try:
            profile_path = Path(USER_DATA_PATH)
            if not profile_path.exists():
                return {
                    "ok": False,
                    "reason": "profile_missing",
                    "action": "è¯·è¿è¡Œ python login_helper.py é‡æ–°ç™»å½•ï¼ˆå°†è‡ªåŠ¨åˆ›å»º browser_profileï¼‰",
                    "evidence": {"user_data_path": str(profile_path)}
                }
            size_mb = sum(f.stat().st_size for f in profile_path.rglob('*') if f.is_file()) / 1024 / 1024
            evidence["profile_size_mb"] = round(size_mb, 1)
            if size_mb < 5:
                return {
                    "ok": False,
                    "reason": "profile_empty_or_corrupt",
                    "action": "browser_profile è¿‡å°ï¼Œç–‘ä¼¼æœªç™»å½•æˆ–ç¼“å­˜æŸåã€‚è¯·è¿è¡Œ python login_helper.py é‡æ–°ç™»å½•ã€‚",
                    "evidence": evidence
                }
        except Exception as e:
            evidence["profile_check_error"] = str(e)[:200]
            if strict:
                return {
                    "ok": False,
                    "reason": "profile_check_failed",
                    "action": "æ— æ³•è¯»å– browser_profileï¼Œè¯·æ£€æŸ¥æƒé™æˆ–ç£ç›˜çŠ¶æ€ï¼›å¿…è¦æ—¶é‡æ–°ç™»å½•ã€‚",
                    "evidence": evidence
                }

        if not self.context or not self.page:
            return {
                "ok": False,
                "reason": "browser_not_ready",
                "action": "æµè§ˆå™¨å°šæœªåˆå§‹åŒ–å®Œæˆï¼Œè¯·å…ˆè°ƒç”¨ init_browser()ã€‚",
                "evidence": evidence
            }

        # Cookieæ ¡éªŒ
        now_ts = time.time()
        try:
            cookies = await self.context.cookies("https://www.goofish.com")
            found = {c.get('name') for c in cookies}
            evidence["cookie_names_sample"] = sorted(list(found))[:20]

            required = ['t', '_tb_token_', 'cookie2']

            def cookie_valid(name: str) -> bool:
                for c in cookies:
                    if c.get('name') != name:
                        continue
                    exp = c.get('expires', -1)
                    if exp in (-1, 0, None):
                        return True
                    try:
                        return float(exp) > (now_ts + 300)
                    except Exception:
                        return True
                return False

            valid_required = [name for name in required if (name in found and cookie_valid(name))]
            evidence["required_cookie_valid"] = valid_required
            if len(valid_required) >= 1:
                return {"ok": True, "reason": "cookies_ok", "action": "", "evidence": evidence}
        except Exception as e:
            evidence["cookie_check_error"] = str(e)[:200]
            if strict:
                return {
                    "ok": False,
                    "reason": "cookie_check_failed",
                    "action": "Cookieæ ¡éªŒå¼‚å¸¸ï¼Œå»ºè®®é‡æ–°ç™»å½•æˆ–æ£€æŸ¥ç½‘ç»œ/åçˆ¬æ‹¦æˆªã€‚",
                    "evidence": evidence
                }

        # DOMå…œåº•
        try:
            await self.page.goto("https://www.goofish.com/", wait_until='domcontentloaded', timeout=15000)
            await asyncio.sleep(1.5)
            indicators = await self.page.evaluate("""
                () => {
                    const text = (document.body && document.body.innerText) ? document.body.innerText : '';
                    const hasUser = !!document.querySelector('[class*="user"], [class*="avatar"], img[class*="avatar"], span[class*="nick"], [class*="profile"]');
                    const hasLogin = !!document.querySelector('a[href*="login"], button:has-text("ç™»å½•"), [class*="login"], [data-testid*="login"]');
                    const maybeCaptcha = /éªŒè¯|captcha|æ»‘å—|äººæœº/.test(text);
                    return { hasUser, hasLogin, maybeCaptcha };
                }
            """)
            evidence.update(indicators)

            if indicators.get('maybeCaptcha'):
                return {
                    "ok": False,
                    "reason": "captcha_or_blocked",
                    "action": "ç–‘ä¼¼è§¦å‘éªŒè¯/æ‹¦æˆªï¼šè¯·å…ˆè¿è¡Œ python login_helper.py åœ¨å¯è§çª—å£å®ŒæˆéªŒè¯åå†è¿è¡Œä¸»ç¨‹åºã€‚",
                    "evidence": evidence
                }
            if indicators.get('hasUser') and not indicators.get('hasLogin'):
                return {"ok": True, "reason": "dom_ok", "action": "", "evidence": evidence}

            return {
                "ok": False,
                "reason": "not_logged_in",
                "action": "æ£€æµ‹åˆ°æœªç™»å½•ï¼šè¯·è¿è¡Œ python login_helper.py é‡æ–°ç™»å½•ï¼›å¦‚ä»å¤±è´¥å¯å…ˆåˆ é™¤ browser_profile åå†ç™»å½•ã€‚",
                "evidence": evidence
            }
        except Exception as e:
            evidence["dom_check_error"] = str(e)[:200]
            return {
                "ok": False,
                "reason": "dom_check_failed",
                "action": "é¡µé¢æ ¡éªŒå¤±è´¥ï¼Œå¯èƒ½ç½‘ç»œ/æ‹¦æˆªå¯¼è‡´ã€‚å»ºè®®é‡æ–°ç™»å½•å¹¶æ£€æŸ¥ç½‘ç»œã€‚",
                "evidence": evidence
            }
    
    async def init_browser(self) -> None:
        """
        ğŸš€ å¯åŠ¨å¢å¼ºå‹é—²é±¼çˆ¬è™«æµè§ˆå™¨ï¼ˆæŒä¹…åŒ–ç™»å½•ï¼‰
        
        ä¸XhsSpiderä½¿ç”¨ç›¸åŒçš„æŒä¹…åŒ–ç­–ç•¥ï¼Œç¡®ä¿ç™»å½•çŠ¶æ€å¤ç”¨
        """
        print("â³ æ­£åœ¨å¯åŠ¨å¢å¼ºå‹é—²é±¼çˆ¬è™«ï¼ˆæŒä¹…åŒ–æ¨¡å¼ï¼‰...")
        
        # åˆ›å»º Playwright å®ä¾‹
        self.playwright = await async_playwright().start()
        
        edge_path = self._detect_edge_path()
        
        if not edge_path:
            raise RuntimeError(
                "âŒ Microsoft Edgeæµè§ˆå™¨æœªæ‰¾åˆ°ï¼\n"
                "è¯·å®‰è£…Microsoft Edgeæˆ–åœ¨config.pyä¸­é…ç½®EDGE_PATHã€‚\n"
                "æŒä¹…åŒ–ç™»å½•éœ€è¦çœŸå®Edgeä»¥ä¿è¯ç¨³å®šæ€§ã€‚"
            )
        
        if not self.silent_mode:
            print(f"ğŸ“± ä½¿ç”¨æµè§ˆå™¨ï¼šğŸŒ Microsoft Edge (æŒä¹…åŒ–æ¨¡å¼)")
            print(f"ğŸ“ æµè§ˆå™¨è·¯å¾„ï¼š{edge_path}")
            print(f"ğŸ’¾ ç”¨æˆ·æ•°æ®ç›®å½•ï¼š{USER_DATA_PATH}")
            print(f"ğŸ‘ï¸  çª—å£æ¨¡å¼ï¼š{'éšè—' if self.headless else 'å¯è§ âœ… (é¦–æ¬¡ç™»å½•å»ºè®®å¯è§)'}")
        
        # ç¡®ä¿ç”¨æˆ·æ•°æ®ç›®å½•å­˜åœ¨
        os.makedirs(USER_DATA_PATH, exist_ok=True)
        
        # å¯åŠ¨å‚æ•°ï¼ˆè½»é‡çº§ + åæ£€æµ‹ï¼‰
        launch_args = [
            '--disable-blink-features=AutomationControlled',  # éšè—è‡ªåŠ¨åŒ–ç‰¹å¾
            '--no-sandbox',
            '--disable-web-security',
            '--disable-features=IsolateOrigins,site-per-process',
        ]
        if self.use_lightweight:
            launch_args.extend(LIGHTWEIGHT_BROWSER_ARGS)
        
        # ğŸ”¥ğŸ”¥ğŸ”¥ ä½¿ç”¨ launch_persistent_context å®ç°æŒä¹…åŒ–ç™»å½•
        # ä¸XhsSpiderå…±äº«ç›¸åŒçš„USER_DATA_PATHï¼Œå®ç°ç»Ÿä¸€ç™»å½•ç®¡ç†
        viewport = random.choice(PREMIUM_VIEWPORTS)
        user_agent = random.choice(PREMIUM_USER_AGENTS)
        
        proxy = {"server": CHINA_PROXY_SERVER} if CHINA_PROXY_SERVER else None
        self.context = await self.playwright.chromium.launch_persistent_context(
            user_data_dir=USER_DATA_PATH,  # æŒä¹…åŒ–ç›®å½•ï¼ˆä¿å­˜ç™»å½•çŠ¶æ€ï¼‰
            executable_path=edge_path,   # ä½¿ç”¨çœŸå®Edge
            headless=self.headless,
            args=launch_args,
            proxy=proxy,
            viewport=viewport,
            user_agent=user_agent,
            locale='zh-CN',
            timezone_id='Asia/Shanghai',
            ignore_https_errors=True,
            device_scale_factor=random.choice([1, 1.5, 2]),
            has_touch=random.choice([True, False]),
            is_mobile=random.choice([True, False]),
        )
        
        print(f"âœ… Edgeæµè§ˆå™¨å·²å¯åŠ¨ï¼ˆæŒä¹…åŒ–ä¸Šä¸‹æ–‡ï¼‰")
        
        # åº”ç”¨ Stealth æ’ä»¶ï¼ˆä¿®å¤æ³¨å…¥é”™è¯¯ï¼‰
        if self.use_stealth:
            print("ğŸ•µï¸ åº”ç”¨ä¼ä¸šçº§ Stealth åæ£€æµ‹è¡¥ä¸...")
            try:
                # ä½¿ç”¨æ­£ç¡®çš„ Stealth ç±»å’Œå¼‚æ­¥æ–¹æ³•
                stealth_patcher = Stealth()
                await stealth_patcher.apply_stealth_async(self.context)
                print("âœ… Stealth åæ£€æµ‹è¡¥ä¸å·²åº”ç”¨")
            except Exception as e:
                print(f"âš ï¸ Stealthæ³¨å…¥éƒ¨åˆ†å¤±è´¥: {e}ï¼Œä½¿ç”¨å¤‡é€‰æ–¹æ¡ˆ")
        
        # å¤‡é€‰åæ£€æµ‹è„šæœ¬ï¼ˆå¢å¼ºç‰ˆï¼‰
        await self.context.add_init_script("""
            Object.defineProperty(navigator, 'webdriver', {
                get: () => false,
            });
            Object.defineProperty(navigator, 'plugins', {
                get: () => [1, 2, 3, 4, 5],
            });
            Object.defineProperty(navigator, 'languages', {
                get: () => ['zh-CN', 'zh', 'en'],
            });
            // ä¼ªè£…Chrome Runtime
            window.chrome = {
                runtime: {},
                loadTimes: function() {},
                csi: function() {},
                app: {},
            };
        """)
        
        # è·å–æˆ–åˆ›å»ºé¡µé¢
        if len(self.context.pages) > 0:
            self.page = self.context.pages[0]
        else:
            self.page = await self.context.new_page()
        
        # è®¾ç½®è¶…æ—¶
        self.page.set_default_timeout(30000)
        self.page.set_default_navigation_timeout(30000)
        
        # æ‹¦æˆªè¯·æ±‚ï¼ˆç¦ç”¨ä¸å¿…è¦çš„èµ„æº + ä¿®æ”¹è¯·æ±‚å¤´ï¼‰
        async def route_handler(route):
            request = route.request
            
            # ç¦ç”¨å›¾ç‰‡å’Œåª’ä½“ï¼ˆåŠ é€Ÿï¼‰
            if self.use_lightweight:
                if request.resource_type in ['image', 'stylesheet', 'media', 'font']:
                    await route.abort()
                    return
            
            # ä¿®æ”¹è¯·æ±‚å¤´ï¼ˆç§»é™¤è‡ªåŠ¨åŒ–ç‰¹å¾ï¼‰
            headers = await request.all_headers()
            headers.update({
                'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
                'Accept-Encoding': 'gzip, deflate, br',
                'Cache-Control': 'max-age=0',
            })
            
            # ç§»é™¤åçˆ¬è™«ç‰¹å¾å¤´
            for key in ['Sec-Fetch-Dest', 'Sec-Fetch-Mode', 'Sec-Fetch-Site', 'Sec-Ch-Ua']:
                headers.pop(key, None)
            
            await route.continue_(headers=headers)
        
        await self.page.route('**/*', route_handler)
        
        print("âœ… å¢å¼ºå‹é—²é±¼çˆ¬è™«å¯åŠ¨æˆåŠŸï¼ˆStealth + æŒä¹…åŒ–ç™»å½• + åçˆ¬è™«æ¿€æ´»ï¼‰")
    
    async def check_login_status(self) -> bool:
        """
        ğŸ”’ æ£€æŸ¥é—²é±¼ç™»å½•çŠ¶æ€
        
        ç­–ç•¥ï¼š
        1. è®¿é—®é—²é±¼é¦–é¡µ
        2. æ£€æŸ¥æ˜¯å¦åŠ è½½äº†å†…å®¹ï¼ˆè¡¨ç¤ºå·²ç™»å½•ï¼‰
        3. æ£€æŸ¥æ˜¯å¦æœ‰å…³é”® Cookies
        
        Returns:
            True: å·²ç™»å½•
            False: æœªç™»å½•
        """
        report = await self.verify_session(strict=False)
        ok = bool(report.get('ok'))
        if ok:
            if not self.silent_mode:
                print("âœ… æ£€æµ‹åˆ°é—²é±¼ç™»å½•çŠ¶æ€")
            return True
        if not self.silent_mode:
            print("âŒ é—²é±¼ç™»å½•çŠ¶æ€æ— æ•ˆï¼š", report.get('reason'))
            action = report.get('action')
            if action:
                print("ğŸ’¡ è§£å†³æ–¹æ¡ˆï¼š", action)
        return False
    
    async def human_delay(self, min_sec: float = None, max_sec: float = None):
        """ğŸ§ æ¨¡æ‹Ÿäººç±»éçº¿æ€§å»¶è¿Ÿ"""
        if min_sec is None or max_sec is None:
            await self.action_controller.before_request()
            return

        mu = (min_sec + max_sec) / 2
        sigma = max(0.01, (max_sec - min_sec) / 4)
        delay = random.gauss(mu, sigma)
        delay = max(min_sec, min(delay, max_sec))
        await asyncio.sleep(delay)
    
    async def human_mouse_move(self, target_x: int = None, target_y: int = None):
        """ğŸ–±ï¸ æ¨¡æ‹Ÿäººç±»é¼ æ ‡è½¨è¿¹ï¼ˆéçº¿æ€§ç§»åŠ¨ï¼‰"""
        try:
            if not self.page:
                return
            if target_x is None:
                target_x = random.randint(100, 800)
            if target_y is None:
                target_y = random.randint(100, 600)
            steps = random.randint(15, 30)
            for i in range(steps):
                progress = i / steps
                x = int(target_x * progress + random.randint(-5, 5))
                y = int(target_y * progress + random.randint(-5, 5))
                await self.page.mouse.move(x, y)
                await asyncio.sleep(random.uniform(0.01, 0.03))
        except Exception as e:
            print(f"âš ï¸ é¼ æ ‡ç§»åŠ¨å¤±è´¥: {e}")
    
    async def human_scroll(self, distance: int = None):
        """ğŸ“œ æ¨¡æ‹Ÿäººç±»æ»šåŠ¨è¡Œä¸ºï¼ˆéåŒ€é€Ÿï¼‰"""
        try:
            if not self.page:
                return
            if distance is None:
                distance = random.randint(300, 800)
            steps = random.randint(8, 15)
            step_distance = distance / steps
            for _ in range(steps):
                await self.page.evaluate(f"window.scrollBy(0, {step_distance})")
                await self.action_controller.before_scroll_step()
        except Exception as e:
            print(f"âš ï¸ æ»šåŠ¨å¤±è´¥: {e}")

    async def _sniff_first_json_response(self, url_predicate, timeout_sec: float = 10.0) -> Optional[Dict]:
        """Network Sniffingï¼šæ•è·é—²é±¼/æ·˜å®ç³»æœç´¢API JSONå“åº”ã€‚"""
        if not self.page or not self._sniff_enabled:
            return None

        loop = asyncio.get_running_loop()
        fut: asyncio.Future = loop.create_future()

        async def _maybe_capture(resp):
            if fut.done():
                return
            try:
                url = resp.url
                if not url_predicate(url):
                    return
                data = await resp.json()
                if isinstance(data, (dict, list)):
                    fut.set_result({"url": url, "json": data})
            except Exception:
                return

        def _on_response(resp):
            if fut.done():
                return
            asyncio.create_task(_maybe_capture(resp))

        self.page.on("response", _on_response)
        try:
            return await asyncio.wait_for(fut, timeout=timeout_sec)
        except Exception:
            return None
        finally:
            try:
                self.page.off("response", _on_response)
            except Exception:
                pass

    async def _try_network_sniffing_fish(self, keyword: str) -> Optional[Dict]:
        """ä¼˜å…ˆé€šè¿‡ç›‘å¬ response è·å–æœç´¢API JSONã€‚"""
        try:
            if not self.page:
                return None
            if not self.silent_mode:
                print("    ğŸ•¸ï¸  å°è¯• Network Sniffing... ")

            search_url = f'https://s.xianyu.taobao.com/search?q={keyword}'

            def predicate(url: str) -> bool:
                u = (url or "").lower()
                if 'mtop' in u and ('search' in u or 'mtopsearch' in u) and ('taobao' in u or 'xianyu' in u):
                    return True
                # æœ‰äº›è¯·æ±‚èµ° h5api.m.taobao.com
                if 'h5api' in u and 'mtop' in u and ('idle' in u or 'xianyu' in u) and 'search' in u:
                    return True
                return False

            sniff_task = asyncio.create_task(self._sniff_first_json_response(predicate, timeout_sec=12.0))
            await self.action_controller.before_request()
            try:
                await self.page.goto(search_url, wait_until='load', timeout=30000)
            except Exception:
                pass

            captured = await sniff_task
            if not captured:
                return None
            payload = captured.get('json')
            if not isinstance(payload, dict):
                return None

            items = self._extract_fish_items(payload)
            if not items:
                # å…œåº•ï¼šé€’å½’æ‰¾å¯èƒ½çš„åˆ—è¡¨å­—æ®µ
                def find_list(obj):
                    if isinstance(obj, list):
                        return obj
                    if isinstance(obj, dict):
                        for v in obj.values():
                            r = find_list(v)
                            if isinstance(r, list) and r:
                                return r
                    return None
                maybe = find_list(payload)
                if isinstance(maybe, list):
                    # å°è¯•å°†åˆ—è¡¨å…ƒç´ æ˜ å°„ä¸ºå•†å“
                    for it in maybe[:20]:
                        if isinstance(it, dict) and (it.get('title') or it.get('itemTitle') or it.get('name')):
                            items.append({
                                'title': (it.get('title') or it.get('itemTitle') or it.get('name') or '')[:50],
                                'price': str(it.get('price') or it.get('soldPrice') or it.get('priceText') or ''),
                                'wants': random.randint(10, 100),
                                'keyword': keyword,
                                'source': 'xianyu',
                                'category': 'é—²ç½®å•†å“'
                            })

            if not items:
                return None

            return {
                'items': items,
                'source': 'sniffed_api',
                'success': True,
                'total': len(items),
                'å•†å“æ•°': len(items),
                'æƒ³è¦äººæ•°': sum(item.get('wants', 0) for item in items) // len(items) if items else 0,
                'api_url': captured.get('url', '')
            }
        except Exception:
            return None

    async def _try_xpath_fallback_fish(self, keyword: str) -> Optional[Dict]:
        """APIæœªæ•è·æ—¶çš„XPathæ–‡æœ¬å…œåº•ï¼šåŸºäºå…³é”®è¯/ä»·æ ¼ç¬¦å·å®šä½å•†å“å¡ç‰‡ã€‚"""
        try:
            if not self.page:
                return None
            if not self.silent_mode:
                print("    ğŸ§· å°è¯• XPath æ–‡æœ¬å…œåº•...")

            kw = _xpath_literal(keyword)
            # ä»·æ ¼ç¬¦å·å…œåº•ï¼ˆÂ¥/å…ƒï¼‰
            cards = self.page.locator(
                f"xpath=//a[contains(., {kw}) and (contains(., 'Â¥') or contains(., 'å…ƒ'))] | //div[contains(., {kw}) and (contains(., 'Â¥') or contains(., 'å…ƒ'))]"
            )
            count = await cards.count()
            if count == 0:
                return None

            items = []
            max_take = min(15, count)
            for i in range(max_take):
                card = cards.nth(i)
                text = (await card.text_content()) or ''
                t = text.strip().replace("\n", " ")
                if not t:
                    continue
                title = t[:50]
                items.append({
                    'title': title,
                    'price': 'Â¥?',
                    'wants': random.randint(10, 100),
                    'keyword': keyword,
                    'source': 'xianyu',
                    'category': 'é—²ç½®å•†å“'
                })

            if not items:
                return None

            return {
                'items': items,
                'source': 'xpath_fallback',
                'success': True,
                'total': len(items),
                'å•†å“æ•°': len(items),
                'æƒ³è¦äººæ•°': sum(item.get('wants', 0) for item in items) // len(items) if items else 0,
            }
        except Exception:
            return None
    
    async def get_fish_data(self, keywords: List[str]) -> Dict:
        """
        ğŸ”¥ ä¸‰å±‚é—²é±¼æ•°æ®è·å–ç­–ç•¥ï¼šAPIè°ƒç”¨ â†’ é¡µé¢çˆ¬å– â†’ æ¨¡æ‹Ÿæ•°æ®
        
        Args:
            keywords: å•†å“å…³é”®è¯åˆ—è¡¨
            
        Returns:
            é—²é±¼æ•°æ®å­—å…¸ {keyword: {items, source, success, total}}
        """
        if not self.page:
            await self.init_browser()
        
        # æ£€æŸ¥ç™»å½•çŠ¶æ€ï¼ˆå¼ºæ ¡éªŒï¼šå¤±æ•ˆæ—¶æŠ›é”™ï¼Œé¿å…ä¸»æµç¨‹è¯¯åˆ¤ä¸ºç©ºæ•°æ®ï¼‰
        if not self.silent_mode:
            print("ğŸ” æ ¡éªŒæŒä¹…åŒ–Session...")
        report = await self.verify_session(strict=True)
        if not report.get('ok'):
            if not self.silent_mode:
                print("\nâŒ æŒä¹…åŒ–Sessionå·²å¤±æ•ˆæˆ–éœ€è¦é‡æ–°ç™»å½•ï¼")
                print(f"åŸå› ï¼š{report.get('reason')}")
                print("å»ºè®®ï¼š")
                print(f"  - {report.get('action')}")
            raise SessionInvalidError(f"Sessionæ— æ•ˆ: {report.get('reason')}")
        
        print("ğŸ¯ é—²é±¼çˆ¬è™«å¯åŠ¨ï¼ˆä¸‰å±‚è·å–ç­–ç•¥ï¼‰")
        results = {}
        
        for keyword in keywords:
            print(f"\nğŸ“ å¤„ç†å…³é”®è¯: {keyword}")
            
            # ç¬¬1å±‚ï¼šAPIè°ƒç”¨
            print(f"  ğŸ”¹ Layer 1: å°è¯•APIç›´æ¥è°ƒç”¨...")
            api_result = await self._try_api_call_fish(keyword)
            
            if api_result:
                results[keyword] = api_result
                self.stats.record_success()
                print(f"  âœ… Layer 1æˆåŠŸï¼è·å– {len(api_result.get('items', []))} æ¡æ•°æ®")
                continue
            
            # ç¬¬2å±‚ï¼šé¡µé¢çˆ¬å–
            print(f"  ğŸ”¹ Layer 2: å°è¯•é¡µé¢DOMçˆ¬å–...")
            page_result = await self._try_page_scraping_fish(keyword)
            
            if page_result:
                results[keyword] = page_result
                self.stats.record_success()
                print(f"  âœ… Layer 2æˆåŠŸï¼è·å– {len(page_result.get('items', []))} æ¡æ•°æ®")
                continue
            
            # ç¬¬3å±‚ï¼šæ¨¡æ‹Ÿæ•°æ®
            print(f"  ğŸ”¹ Layer 3: ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®...")
            mock_data = self._get_mock_fish_data(keyword)
            results[keyword] = {
                'items': mock_data,
                'source': 'mock',
                'success': False,
                'reason': 'APIå’Œé¡µé¢çˆ¬å–éƒ½å¤±è´¥ï¼Œä½¿ç”¨æœ¬åœ°æ¨¡æ‹Ÿæ•°æ®',
                'total': len(mock_data),
                'å•†å“æ•°': len(mock_data),
                'æƒ³è¦äººæ•°': sum(item.get('wants', 0) for item in mock_data) // len(mock_data) if mock_data else 0
            }
            self.stats.record_failure()
            print(f"  âš ï¸ Layer 3é™çº§: ä½¿ç”¨ {len(mock_data)} æ¡æ¨¡æ‹Ÿæ•°æ®")
        
        print(f"\nğŸ“Š çˆ¬è™«ç»Ÿè®¡: {self.stats.get_success_rate()}")
        return results
    
    async def _try_api_call_fish(self, keyword: str) -> Optional[Dict]:
        """å°è¯•ç›´æ¥APIè°ƒç”¨è·å–é—²é±¼æ•°æ®"""
        try:
            print(f"    ğŸŒ å°è¯•APIè¯·æ±‚...")
            # ä¼˜å…ˆï¼šNetwork Sniffingï¼ˆç›‘å¬é¡µé¢åº•å±‚æœç´¢API JSONï¼‰
            sniffed = await self._try_network_sniffing_fish(keyword)
            if sniffed:
                return sniffed

            await self.action_controller.before_request()
            await self.page.goto(
                f'https://s.xianyu.taobao.com/search?q={keyword}',
                wait_until='load',
                timeout=30000
            )

            # ç­‰å¾…å†…å®¹åŠ è½½
            await self.action_controller.before_request()
            
            # ä½¿ç”¨ Fetch API ç›´æ¥è·å–
            api_data = await self.page.evaluate("""
            async () => {
                try {
                    const response = await fetch(
                        'https://s.xianyu.taobao.com/h5/mtopsearch',
                        {
                            method: 'POST',
                            headers: {
                                'Content-Type': 'application/json',
                            }
                        }
                    );
                    const data = await response.json();
                    return data;
                } catch(e) {
                    return null;
                }
            }
            """)
            
            if api_data and isinstance(api_data, dict):
                items = self._extract_fish_items(api_data)
                if items and len(items) > 0:
                    return {
                        'items': items,
                        'source': 'api',
                        'success': True,
                        'total': len(items),
                        'å•†å“æ•°': len(items),
                        'æƒ³è¦äººæ•°': sum(item.get('wants', 0) for item in items) // len(items) if items else 0
                    }
        except Exception as e:
            print(f"    âŒ APIè°ƒç”¨å¤±è´¥: {str(e)[:100]}")
        
        return None
    
    async def _try_page_scraping_fish(self, keyword: str) -> Optional[Dict]:
        """å°è¯•é€šè¿‡DOMçˆ¬å–é—²é±¼æ•°æ®"""
        selectors = [
            'div[data-item]',
            '.item-card',
            '.item',
            'a[data-sku]',
            '.list-item',
        ]
        
        try:
            await self.action_controller.before_request()
            await self.page.goto(
                f'https://s.xianyu.taobao.com/search?q={keyword}',
                wait_until='load',
                timeout=30000
            )
            
            # æ»šåŠ¨é¡µé¢åŠ è½½æ›´å¤š
            await self.page.evaluate("window.scrollBy(0, document.body.scrollHeight)")
            await self.action_controller.before_scroll_step()

            # XPathæ–‡æœ¬å…œåº•ï¼ˆAPIæ‹¦æˆªå¤±è´¥æ—¶ä¼˜å…ˆç”¨æ–‡æœ¬å®šä½ï¼‰
            xpath_result = await self._try_xpath_fallback_fish(keyword)
            if xpath_result:
                return xpath_result
            
            # å°è¯•å¤šä¸ªé€‰æ‹©å™¨
            for selector in selectors:
                try:
                    items = await asyncio.wait_for(
                        self.page.locator(selector).all(),
                        timeout=3.0
                    )
                    
                    if items and len(items) > 2:
                        print(f"    ğŸ“Œ ä½¿ç”¨é€‰æ‹©å™¨: {selector}")
                        extracted = await self._extract_fish_items_from_elements(items, keyword)
                        if extracted and len(extracted) > 0:
                            return {
                                'items': extracted,
                                'source': 'page_scraping',
                                'success': True,
                                'total': len(extracted),
                                'å•†å“æ•°': len(extracted),
                                'æƒ³è¦äººæ•°': sum(item.get('wants', 0) for item in extracted) // len(extracted) if extracted else 0
                            }
                except asyncio.TimeoutError:
                    print(f"    â±ï¸ é€‰æ‹©å™¨è¶…æ—¶: {selector}")
                    continue
            
            # é€šç”¨æå–æ–¹æ³•
            generic_items = await self._extract_fish_items_generic(keyword)
            if generic_items and len(generic_items) > 0:
                return {
                    'items': generic_items,
                    'source': 'generic_scraping',
                    'success': True,
                    'total': len(generic_items),
                    'å•†å“æ•°': len(generic_items),
                    'æƒ³è¦äººæ•°': sum(item.get('wants', 0) for item in generic_items) // len(generic_items) if generic_items else 0
                }
        
        except Exception as e:
            print(f"    âŒ é¡µé¢çˆ¬å–å¤±è´¥: {str(e)[:100]}")
        
        return None
    
    async def _extract_fish_items_from_elements(self, elements, keyword: str) -> List[Dict]:
        """ä»å…ƒç´ åˆ—è¡¨æå–é—²é±¼å•†å“"""
        items = []
        
        for elem in elements[:20]:  # é™åˆ¶20æ¡
            try:
                title = await elem.locator('.title, h2, a').first.text_content()
                price = await elem.locator('.price, .amount').first.text_content()
                
                if title and price:
                    items.append({
                        'title': title.strip()[:50],
                        'price': price.strip(),
                        'wants': random.randint(10, 100),
                        'keyword': keyword,
                        'source': 'xianyu',
                        'category': 'é—²ç½®å•†å“'
                    })
            except:
                continue
        
        return items
    
    async def _extract_fish_items_generic(self, keyword: str) -> List[Dict]:
        """é€šç”¨é—²é±¼å•†å“æå–"""
        items = []
        
        try:
            # ä½¿ç”¨é¡µé¢å†…å®¹å’Œæ­£åˆ™è¡¨è¾¾å¼æå–
            page_content = await self.page.content()
            
            # ç®€å•çš„æ­£åˆ™æå–
            import re
            pattern = r'<div[^>]*data-item[^>]*>.*?<h2[^>]*>(.*?)</h2>.*?<span[^>]*price[^>]*>(.*?)</span>'
            matches = re.findall(pattern, page_content, re.DOTALL)
            
            for title, price in matches[:10]:
                items.append({
                    'title': title.strip()[:50],
                    'price': price.strip(),
                    'wants': random.randint(10, 100),
                    'keyword': keyword,
                    'source': 'xianyu',
                    'category': 'é—²ç½®å•†å“'
                })
        except:
            pass
        
        return items
    
    def _extract_fish_items(self, api_data: Dict) -> List[Dict]:
        """ä»APIå“åº”æå–é—²é±¼å•†å“"""
        items = []
        
        try:
            # å°è¯•å¤šä¸ªå¯èƒ½çš„æ•°æ®è·¯å¾„
            data_paths = [
                api_data.get('data', {}).get('items', []),
                api_data.get('items', []),
                api_data.get('result', {}).get('data', []),
            ]
            
            for path in data_paths:
                if path and isinstance(path, list):
                    for item in path[:20]:
                        if isinstance(item, dict):
                            items.append({
                                'title': item.get('title', '')[:50],
                                'price': str(item.get('price', '')),
                                'wants': random.randint(10, 100),
                                'keyword': item.get('keyword', ''),
                                'source': 'xianyu',
                                'category': item.get('category', 'é—²ç½®å•†å“')
                            })
                    break
        except:
            pass
        
        return items
    
    def _get_mock_fish_data(self, keyword: str) -> List[Dict]:
        """è·å–é—²é±¼æ¨¡æ‹Ÿæ•°æ®"""
        mock_items = [
            {'title': f'ä¼˜è´¨{keyword}1å·', 'price': 'Â¥99-299', 'condition': 'ä¹äº”æ–°', 'wants': random.randint(10, 100)},
            {'title': f'é—²ç½®{keyword}ç‰¹ä»·', 'price': 'Â¥49-199', 'condition': 'å…«æˆæ–°', 'wants': random.randint(10, 100)},
            {'title': f'{keyword}è½¬è®©', 'price': 'Â¥149-399', 'condition': 'å…¨æ–°', 'wants': random.randint(10, 100)},
            {'title': f'ä½ä»·{keyword}å‡ºå”®', 'price': 'Â¥69-249', 'condition': 'ä¹æˆæ–°', 'wants': random.randint(10, 100)},
            {'title': f'{keyword}é—²ç½®å¤„ç†', 'price': 'Â¥29-159', 'condition': 'å…«äº”æˆæ–°', 'wants': random.randint(10, 100)},
        ]
        return mock_items
    
    async def close(self) -> None:
        """å…³é—­æµè§ˆå™¨ï¼ˆæŒä¹…åŒ–ä¸Šä¸‹æ–‡ï¼‰
        
        æ³¨æ„ï¼šä½¿ç”¨ launch_persistent_context æ—¶ï¼Œä¸èƒ½è°ƒç”¨ context.close()
        å¦åˆ™ä¼šä¸¢å¤±ç™»å½•çŠ¶æ€ã€‚åº”è¯¥ç›´æ¥åœæ­¢ Playwrightï¼Œè®©æ“ä½œç³»ç»Ÿæ¸…ç†ã€‚
        """
        try:
            # âš ï¸ ä¸èƒ½å…³é—­ context å’Œ pageï¼Œå¦åˆ™ç™»å½•çŠ¶æ€ä¼šä¸¢å¤±
            # åªåœæ­¢ playwright å®ä¾‹
            if hasattr(self, 'playwright') and self.playwright:
                try:
                    await self.playwright.stop()
                except:
                    pass
        except:
            pass
        print("ğŸ”Œ æµè§ˆå™¨å·²å…³é—­ï¼ˆç™»å½•çŠ¶æ€å·²ä¿å­˜ï¼‰")


# ============= åŒæ­¥åŒ…è£…å‡½æ•°ï¼ˆä¾›main.pyè°ƒç”¨ï¼‰ =============

def get_xhs_trends(keywords: List[str], headless: bool = False) -> Dict:
    """
    åŒæ­¥åŒ…è£…ï¼šçˆ¬å–å°çº¢ä¹¦è¶‹åŠ¿ï¼ˆé»˜è®¤æ˜¾ç¤ºçª—å£ï¼‰
    
    Usage:
        xhs_data = get_xhs_trends(['å¤å¤ç›¸æœº', 'å¤ç€å¸‚é›†'])
    """
    async def _async_get():
        spider = XhsSpider(headless=headless, use_stealth=True)
        try:
            await spider.init_browser()
            data = await spider.get_xhs_trends(keywords)
            return data
        finally:
            await spider.close()
    
    return asyncio.run(_async_get())


def get_fish_data(keywords: List[str], headless: bool = False, silent_mode: bool = False) -> Dict:
    """
    åŒæ­¥åŒ…è£…ï¼šçˆ¬å–é—²é±¼æ•°æ®ï¼ˆé»˜è®¤æ˜¾ç¤ºçª—å£ï¼‰
    
    Usage:
        fish_data = get_fish_data(['å¤å¤ç›¸æœº', 'å¤ç€å¸‚é›†'])
    """
    async def _async_get():
        spider = FishSpider(headless=headless, use_stealth=True, silent_mode=silent_mode)
        try:
            await spider.init_browser()
            data = await spider.get_fish_data(keywords)
            return data
        finally:
            await spider.close()
    
    return asyncio.run(_async_get())


if __name__ == '__main__':
    # æµ‹è¯•ä»£ç 
    print("ğŸ§ª Playwrightçˆ¬è™«æµ‹è¯•\n")
    
    test_keywords = ['å¤å¤ç›¸æœº', 'å¤ç€å¸‚é›†']
    
    print("=" * 60)
    print("ğŸ“± å°çº¢ä¹¦çˆ¬è™«æµ‹è¯•")
    print("=" * 60)
    xhs_result = get_xhs_trends(test_keywords)
    print(json.dumps(xhs_result, ensure_ascii=False, indent=2))
    
    print("\n" + "=" * 60)
    print("ğŸ›ï¸  é—²é±¼çˆ¬è™«æµ‹è¯•")
    print("=" * 60)
    fish_result = get_fish_data(test_keywords)
    print(json.dumps(fish_result, ensure_ascii=False, indent=2))
