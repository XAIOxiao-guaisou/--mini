"""
ğŸš€ å°çº¢ä¹¦ä¸é—²é±¼æ•°æ®çˆ¬è™«æ¨¡å—
ä½¿ç”¨ Playwright + Stealth å®ç°é«˜çº§åæ£€æµ‹çˆ¬è™«ï¼ˆ2025å¹´é»‘ç§‘æŠ€ï¼‰

ä¼˜åŠ¿ï¼š
- åŸç”ŸWebSocketé©±åŠ¨ï¼Œé€Ÿåº¦å¿«40%
- playwright-stealthè‡ªåŠ¨æŠ¹é™¤WebGL/CanvasæŒ‡çº¹
- BrowserContextéš”ç¦»ï¼Œç±»ä¼¼éšèº«æ¨¡å¼
- åŸç”Ÿæ”¯æŒæ‹¦æˆªå’Œä¿®æ”¹è¯·æ±‚å¤´
"""

import asyncio
import random
import time
import json
from typing import List, Dict, Optional
import os
from pathlib import Path
from config import DELAY_BETWEEN_REQUESTS, USER_DATA_PATH, EDGE_PATH
from .advanced_config import (
    PREMIUM_USER_AGENTS, PREMIUM_VIEWPORTS, LIGHTWEIGHT_BROWSER_ARGS,
    DelayManager, HeaderBuilder, RetryManager, ResponseValidator,
    RequestStats
)

# å¯¼å…¥ Playwright
try:
    from playwright.async_api import async_playwright, Page, Browser, BrowserContext
    from playwright_stealth import Stealth
    HAS_PLAYWRIGHT = True
except ImportError as e:
    print(f"âš ï¸  Playwright æœªå®‰è£…ï¼Œè¯·è¿è¡Œï¼špip install playwright playwright-stealth")
    HAS_PLAYWRIGHT = False


# é«˜çº§User-Agentæ± ï¼ˆ2025å¹´çœŸå®å®¢æˆ·ç«¯ï¼‰
USER_AGENTS = [
    "Mozilla/5.0 (iPhone; CPU iPhone OS 18_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/18.0 Mobile/15E148 Safari/604.1",
    "Mozilla/5.0 (iPhone; CPU iPhone OS 17_1 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.1 Mobile/15E148 Safari/604.1",
    "Mozilla/5.0 (Linux; Android 14; SM-S911B) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.6167.140 Mobile Safari/537.36",
    "Mozilla/5.0 (Linux; Android 15; Pixel 9) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.6167.140 Mobile Safari/537.36",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36",
]

# çœŸå®æµè§ˆå™¨æŒ‡çº¹ï¼ˆViewportï¼‰
VIEWPORTS = [
    {"width": 1920, "height": 1080},
    {"width": 1440, "height": 900},
    {"width": 1280, "height": 800},
    {"width": 1366, "height": 768},
]


class XhsSpider:
    """
    ğŸ¯ å°çº¢ä¹¦çˆ¬è™« - ä¼ä¸šçº§ Playwright ç‰ˆæœ¬ï¼ˆ2025é»‘ç§‘æŠ€ï¼‰
    
    ç‰¹æ€§ï¼š
    - æ™ºèƒ½åçˆ¬è™«å¯¹æŠ—ï¼ˆUser-Agentè½®æ¢ã€éšæœºå»¶è¿Ÿã€è¯·æ±‚å¤´ä¼ªè£…ï¼‰
    - è‡ªåŠ¨é‡è¯•æœºåˆ¶ï¼ˆæŒ‡æ•°é€€é¿ï¼‰
    - æ€§èƒ½ä¼˜åŒ–ï¼ˆç¦ç”¨å›¾ç‰‡ã€å¹¶è¡ŒåŠ è½½ï¼‰
    - å¤šé€‰æ‹©å™¨é™çº§
    - è¯¦ç»†çš„ç»Ÿè®¡å’Œæ—¥å¿—
    """
    
    def __init__(self, headless: bool = False, use_stealth: bool = True, use_lightweight: bool = True):
        """
        åˆå§‹åŒ–å°çº¢ä¹¦çˆ¬è™«
        
        Args:
            headless: æ— å¤´æ¨¡å¼ï¼ˆé»˜è®¤Falseï¼Œæ˜¾ç¤ºçª—å£ï¼‰
            use_stealth: å¯ç”¨åæ£€æµ‹
            use_lightweight: è½»é‡çº§æ¨¡å¼ï¼ˆç¦ç”¨å›¾ç‰‡ã€åŠ é€Ÿï¼‰
        """
        if not HAS_PLAYWRIGHT:
            raise ImportError("Playwrightæœªå®‰è£…")
        
        self.headless = headless
        self.use_stealth = use_stealth
        self.use_lightweight = use_lightweight
        self.browser: Optional[Browser] = None
        self.context: Optional[BrowserContext] = None
        self.page: Optional[Page] = None
        
        # åˆå§‹åŒ–å·¥å…·
        self.delay_manager = DelayManager(min_delay=1.0, max_delay=3.0)
        self.retry_manager = RetryManager(max_retries=5)
        self.stats = RequestStats()
        self.playwright = None
    
    async def init_browser(self) -> None:
        """
        ğŸš€ å¯åŠ¨æµè§ˆå™¨ + æŒä¹…åŒ–ç™»å½• + åº”ç”¨é«˜çº§åçˆ¬è™«é…ç½®
        
        å·¥ä½œæµç¨‹ï¼š
        1. ä½¿ç”¨ launch_persistent_context ä¿å­˜ç™»å½•çŠ¶æ€
        2. åº”ç”¨ Stealth åæ£€æµ‹è¡¥ä¸
        3. æ³¨å…¥åæ£€æµ‹ JavaScript
        4. æ‹¦æˆªå’Œä¿®æ”¹è¯·æ±‚å¤´
        5. å¯ç”¨äººç±»è¡Œä¸ºæ¨¡æ‹Ÿ
        """
        print("â³ æ­£åœ¨å¯åŠ¨å¢å¼ºå‹ Playwright æµè§ˆå™¨ï¼ˆæŒä¹…åŒ–æ¨¡å¼ï¼‰...")
        
        # åˆ›å»º Playwright å®ä¾‹
        self.playwright = await async_playwright().start()
        
        # ğŸ”¥ ä»…ä½¿ç”¨Edgeæµè§ˆå™¨ï¼ˆChromiumå†…æ ¸ï¼Œæ›´ç¨³å®šï¼‰
        edge_paths = [
            EDGE_PATH,  # configä¸­é…ç½®çš„è·¯å¾„
            r"C:\Program Files\Microsoft\Edge\Application\msedge.exe",
            r"C:\Program Files (x86)\Microsoft\Edge\Application\msedge.exe",
        ]
        
        edge_path = None
        for path in edge_paths:
            if os.path.exists(path):
                edge_path = path
                break
        
        if not edge_path:
            raise RuntimeError(
                "âŒ Microsoft Edgeæµè§ˆå™¨æœªæ‰¾åˆ°ï¼\n"
                "è¯·å®‰è£…Microsoft Edgeæˆ–åœ¨config.pyä¸­é…ç½®EDGE_PATHã€‚\n"
                "æŒä¹…åŒ–ç™»å½•éœ€è¦çœŸå®Edgeä»¥ä¿è¯ç¨³å®šæ€§ã€‚"
            )
        
        print(f"ğŸ“± ä½¿ç”¨æµè§ˆå™¨ï¼šğŸŒ Microsoft Edge (æŒä¹…åŒ–æ¨¡å¼)")
        print(f"ğŸ’¾ æµè§ˆå™¨è·¯å¾„ï¼š{edge_path}")
        print(f"ğŸ’¾ ç”¨æˆ·æ•°æ®ç›®å½•ï¼š{USER_DATA_PATH}")
        print(f"ğŸ‘ï¸  çª—å£æ¨¡å¼ï¼š{'éšè—' if self.headless else 'å¯è§ âœ… (é¦–æ¬¡ç™»å½•å»ºè®®å¯è§)'}")
        
        # æ£€æŸ¥ browser_profile æ˜¯å¦å­˜åœ¨å’Œæ•°æ®å¤§å°
        profile_path = Path(USER_DATA_PATH)
        if profile_path.exists():
            try:
                size_mb = sum(f.stat().st_size for f in profile_path.rglob('*') if f.is_file()) / 1024 / 1024
                if size_mb > 1:
                    print(f"ğŸ“¦ æ£€æµ‹åˆ°å·²ä¿å­˜çš„æµè§ˆå™¨æ•°æ®ï¼ˆ{size_mb:.1f}MBï¼‰- å°†å¤ç”¨ç™»å½•çŠ¶æ€")
                else:
                    print(f"âš ï¸  æµè§ˆå™¨æ•°æ®ç›®å½•å­˜åœ¨ä½†ä¸ºç©º - é¦–æ¬¡ä½¿ç”¨ï¼Œéœ€è¦ç™»å½•")
            except:
                pass
        else:
            print(f"â„¹ï¸  åˆ›å»ºæ–°çš„æµè§ˆå™¨æ•°æ®ç›®å½•")
        
        # ç¡®ä¿ç”¨æˆ·æ•°æ®ç›®å½•å­˜åœ¨
        os.makedirs(USER_DATA_PATH, exist_ok=True)
        
        # å¯åŠ¨å‚æ•°ï¼ˆè½»é‡çº§ + åæ£€æµ‹ï¼‰
        launch_args = [
            '--disable-blink-features=AutomationControlled',  # éšè—è‡ªåŠ¨åŒ–ç‰¹å¾
            '--no-sandbox',
            '--disable-web-security',
            '--disable-features=IsolateOrigins,site-per-process',
        ]
        if self.use_lightweight:
            launch_args.extend(LIGHTWEIGHT_BROWSER_ARGS)
        
        # ğŸ”¥ğŸ”¥ğŸ”¥ ä½¿ç”¨ launch_persistent_context å®ç°æŒä¹…åŒ–ç™»å½•
        # è¿™ä¼šå°†æ‰€æœ‰Cookieã€LocalStorageã€Sessionä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶å¤¹
        viewport = random.choice(PREMIUM_VIEWPORTS)
        user_agent = random.choice(PREMIUM_USER_AGENTS)
        
        self.context = await self.playwright.chromium.launch_persistent_context(
            user_data_dir=USER_DATA_PATH,  # æŒä¹…åŒ–ç›®å½•ï¼ˆä¿å­˜ç™»å½•çŠ¶æ€ï¼‰
            executable_path=edge_path,   # ä½¿ç”¨Edge
            headless=self.headless,
            args=launch_args,
            viewport=viewport,
            user_agent=user_agent,
            locale='zh-CN',
            timezone_id='Asia/Shanghai',
            ignore_https_errors=True,
            device_scale_factor=random.choice([1, 1.5, 2]),
            has_touch=random.choice([True, False]),
            is_mobile=random.choice([True, False]),
        )
        
        print(f"âœ… Edgeæµè§ˆå™¨å·²å¯åŠ¨ï¼ˆæŒä¹…åŒ–ä¸Šä¸‹æ–‡ï¼‰")
        
        # åº”ç”¨ Stealth æ’ä»¶ï¼ˆä¿®å¤æ³¨å…¥é”™è¯¯ï¼‰
        if self.use_stealth:
            print("ğŸ•µï¸ åº”ç”¨ä¼ä¸šçº§ Stealth åæ£€æµ‹è¡¥ä¸...")
            try:
                # ä½¿ç”¨æ­£ç¡®çš„ Stealth ç±»å’Œå¼‚æ­¥æ–¹æ³•
                stealth_patcher = Stealth()
                await stealth_patcher.apply_stealth_async(self.context)
                print("âœ… Stealth åæ£€æµ‹è¡¥ä¸å·²åº”ç”¨")
            except Exception as e:
                print(f"âš ï¸ Stealthæ³¨å…¥éƒ¨åˆ†å¤±è´¥: {e}ï¼Œä½¿ç”¨å¤‡é€‰æ–¹æ¡ˆ")
        
        # å¤‡é€‰åæ£€æµ‹è„šæœ¬ï¼ˆå¢å¼ºç‰ˆï¼‰
        await self.context.add_init_script("""
            Object.defineProperty(navigator, 'webdriver', {
                get: () => false,
            });
            Object.defineProperty(navigator, 'plugins', {
                get: () => [1, 2, 3, 4, 5],
            });
            Object.defineProperty(navigator, 'languages', {
                get: () => ['zh-CN', 'zh', 'en'],
            });
            const originalPermissionQuery = window.navigator.permissions.query;
            window.navigator.permissions.query = (parameters) => (
                parameters.name === 'notifications' ?
                    Promise.resolve({ state: Notification.permission }) :
                    originalPermissionQuery(parameters)
            );
            // ä¼ªè£…Chrome Runtime
            window.chrome = {
                runtime: {},
                loadTimes: function() {},
                csi: function() {},
                app: {},
            };
        """)
        
        # è·å–æˆ–åˆ›å»ºé¡µé¢
        if len(self.context.pages) > 0:
            self.page = self.context.pages[0]
        else:
            self.page = await self.context.new_page()
        
        # è®¾ç½®è¶…æ—¶
        self.page.set_default_timeout(30000)
        self.page.set_default_navigation_timeout(30000)
        
        # æ‹¦æˆªè¯·æ±‚ï¼ˆç¦ç”¨ä¸å¿…è¦çš„èµ„æº + ä¿®æ”¹è¯·æ±‚å¤´ï¼‰
        async def route_handler(route):
            request = route.request
            
            # ç¦ç”¨å›¾ç‰‡å’Œåª’ä½“ï¼ˆåŠ é€Ÿï¼‰
            if self.use_lightweight:
                if request.resource_type in ['image', 'stylesheet', 'media', 'font']:
                    await route.abort()
                    return
            
            # ä¿®æ”¹è¯·æ±‚å¤´ï¼ˆç§»é™¤è‡ªåŠ¨åŒ–ç‰¹å¾ï¼‰
            headers = await request.all_headers()
            headers.update({
                'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
                'Accept-Encoding': 'gzip, deflate, br',
                'Cache-Control': 'max-age=0',
            })
            
            # ç§»é™¤åçˆ¬è™«ç‰¹å¾å¤´
            for key in ['Sec-Fetch-Dest', 'Sec-Fetch-Mode', 'Sec-Fetch-Site', 'Sec-Ch-Ua']:
                headers.pop(key, None)
            
            await route.continue_(headers=headers)
        
        await self.page.route('**/*', route_handler)
        
        print("âœ… å¢å¼ºå‹æµè§ˆå™¨å¯åŠ¨æˆåŠŸï¼ˆStealth + æŒä¹…åŒ–ç™»å½• + åçˆ¬è™«æ¿€æ´»ï¼‰")
    
    async def check_login_status(self) -> bool:
        """
        ğŸ”’ æ£€æŸ¥å½“å‰æ˜¯å¦å¤„äºç™»å½•çŠ¶æ€
        
        ç­–ç•¥ï¼š
        1. è®¿é—®å°çº¢ä¹¦é¦–é¡µ
        2. æ£€æŸ¥æ˜¯å¦åŠ è½½äº†å†…å®¹ï¼ˆè¡¨ç¤ºå·²ç™»å½•ï¼‰
        3. æ£€æŸ¥æ˜¯å¦æœ‰å…³é”® Cookies
        
        Returns:
            True: å·²ç™»å½•
            False: æœªç™»å½•
        """
        try:
            if not self.page:
                return False
            
            # æ–¹æ³•1ï¼šç›´æ¥æ£€æŸ¥å…³é”® Cookiesï¼ˆæœ€å¿«æœ€å¯é ï¼‰
            cookies = await self.context.cookies()
            required_cookies = ['a1', 'webId', 'web_session']
            found_cookies = {cookie['name'] for cookie in cookies}
            
            has_required_cookies = any(rc in found_cookies for rc in required_cookies)
            if has_required_cookies:
                print("âœ… æ£€æµ‹åˆ°ç™»å½•çŠ¶æ€ï¼ˆåŸºäº Cookiesï¼‰")
                return True
            
            # æ–¹æ³•2ï¼šè®¿é—®é¡µé¢å¹¶æ£€æŸ¥å†…å®¹åŠ è½½æƒ…å†µ
            await self.page.goto("https://www.xiaohongshu.com/", wait_until='domcontentloaded', timeout=10000)
            await asyncio.sleep(2)
            
            # æ£€æŸ¥æ˜¯å¦åŠ è½½äº†ç”¨æˆ·å†…å®¹æˆ–å‘ç°ä¿¡æ¯ï¼ˆè¡¨ç¤ºå·²è®¤è¯ï¼‰
            content_indicators = await self.page.evaluate("""
                () => {
                    const result = {
                        hasContent: false,
                        hasUserData: false,
                        hasAuthHeader: false,
                    };
                    
                    // æ£€æŸ¥æ˜¯å¦æœ‰å†…å®¹åŠ è½½ï¼ˆç¬”è®°åˆ—è¡¨ã€æ¨èä¿¡æ¯ï¼‰
                    const contentItems = document.querySelectorAll('[class*="feed"], [class*="card"], [class*="note"], article');
                    result.hasContent = contentItems.length > 0;
                    
                    // æ£€æŸ¥ç”¨æˆ·ç›¸å…³æ•°æ®
                    result.hasUserData = !!document.querySelector('[class*="user"], [class*="avatar"]');
                    
                    // æ£€æŸ¥ localStorage ä¸­æ˜¯å¦æœ‰ç™»å½•ä¿¡æ¯
                    if (typeof localStorage !== 'undefined') {
                        const keys = Object.keys(localStorage);
                        result.hasAuthHeader = keys.some(k => k.includes('user') || k.includes('login') || k.includes('auth'));
                    }
                    
                    return result;
                }
            """)
            
            if content_indicators['hasContent'] or content_indicators['hasUserData']:
                print("âœ… æ£€æµ‹åˆ°ç™»å½•çŠ¶æ€ï¼ˆé¡µé¢å†…å®¹åŠ è½½æˆåŠŸï¼‰")
                return True
            
            print("âŒ æ£€æµ‹åˆ°è´¦å·æœªç™»å½•æˆ–é¡µé¢åŠ è½½å¤±è´¥")
            print("   æç¤ºï¼šå¦‚æœåå¤å‡ºç°æ­¤æç¤ºï¼Œè¯·è¿è¡Œ python login_helper.py é‡æ–°ç™»å½•")
            return False
            
        except Exception as e:
            print(f"âš ï¸  ç™»å½•çŠ¶æ€æ£€æŸ¥å¼‚å¸¸ï¼š{e}")
            # å¼‚å¸¸æ—¶å‡è®¾å·²ç™»å½•ï¼Œç»§ç»­æ‰§è¡Œ
            return True
            return False
            
        except Exception as e:
            print(f"âš ï¸ ç™»å½•çŠ¶æ€æ£€æŸ¥å¤±è´¥: {e}")
            return False
    
    async def human_delay(self, min_sec: float = None, max_sec: float = None):
        """
        ğŸ§ æ¨¡æ‹Ÿäººç±»éçº¿æ€§å»¶è¿Ÿ
        
        Args:
            min_sec: æœ€å°å»¶è¿Ÿç§’æ•°ï¼ˆé»˜è®¤ä½¿ç”¨é…ç½®ï¼‰
            max_sec: æœ€å¤§å»¶è¿Ÿç§’æ•°ï¼ˆé»˜è®¤ä½¿ç”¨é…ç½®ï¼‰
        """
        if min_sec is None or max_sec is None:
            delay = random.uniform(1.5, 4.0)
        else:
            delay = random.uniform(min_sec, max_sec)
        
        # æ·»åŠ éšæœºçš„å¾®æŠ–åŠ¨
        jitter = random.uniform(0, 0.5)
        await asyncio.sleep(delay + jitter)
    
    async def human_mouse_move(self, target_x: int = None, target_y: int = None):
        """
        ğŸ–±ï¸ æ¨¡æ‹Ÿäººç±»é¼ æ ‡è½¨è¿¹ï¼ˆéçº¿æ€§ç§»åŠ¨ï¼‰
        
        Args:
            target_x: ç›®æ ‡Xåæ ‡ï¼ˆéšæœºå¦‚æœä¸ºNoneï¼‰
            target_y: ç›®æ ‡Yåæ ‡ï¼ˆéšæœºå¦‚æœä¸ºNoneï¼‰
        """
        try:
            if not self.page:
                return
            
            # éšæœºç›®æ ‡ä½ç½®
            if target_x is None:
                target_x = random.randint(100, 800)
            if target_y is None:
                target_y = random.randint(100, 600)
            
            # è´å¡å°”æ›²çº¿å¼ç§»åŠ¨ï¼ˆæ¨¡æ‹Ÿäººç±»ï¼‰
            steps = random.randint(15, 30)
            for i in range(steps):
                progress = i / steps
                # æ·»åŠ éšæœºåç§»
                x = int(target_x * progress + random.randint(-5, 5))
                y = int(target_y * progress + random.randint(-5, 5))
                await self.page.mouse.move(x, y)
                await asyncio.sleep(random.uniform(0.01, 0.03))
        except Exception as e:
            print(f"âš ï¸ é¼ æ ‡ç§»åŠ¨å¤±è´¥: {e}")
    
    async def human_scroll(self, distance: int = None):
        """
        ğŸ“œ æ¨¡æ‹Ÿäººç±»æ»šåŠ¨è¡Œä¸ºï¼ˆéåŒ€é€Ÿï¼‰
        
        Args:
            distance: æ»šåŠ¨è·ç¦»ï¼ˆåƒç´ ï¼Œè´Ÿæ•°å‘ä¸Šï¼Œæ­£æ•°å‘ä¸‹ï¼‰
        """
        try:
            if not self.page:
                return
            
            if distance is None:
                distance = random.randint(300, 800)
            
            # åˆ†æ®µæ»šåŠ¨ï¼Œæ¨¡æ‹Ÿäººç±»
            steps = random.randint(8, 15)
            step_distance = distance / steps
            
            for _ in range(steps):
                await self.page.evaluate(f"window.scrollBy(0, {step_distance})")
                await asyncio.sleep(random.uniform(0.05, 0.15))
        except Exception as e:
            print(f"âš ï¸ æ»šåŠ¨å¤±è´¥: {e}")
    
    async def rotate_user_agent(self):
        """
        ğŸ”„ åŠ¨æ€è½®æ¢User-Agentï¼ˆé™ä½å°ç¦é£é™©ï¼‰
        
        æ³¨æ„ï¼šæŒä¹…åŒ–ä¸Šä¸‹æ–‡ä¸æ”¯æŒåŠ¨æ€æ›´æ”¹UAï¼Œéœ€è¦é‡å¯ä¸Šä¸‹æ–‡
        """
        print("ğŸ’¡ æç¤ºï¼šæŒä¹…åŒ–ä¸Šä¸‹æ–‡ä¸æ”¯æŒåŠ¨æ€æ›´æ”¹UAï¼Œå»ºè®®å®šæœŸé‡å¯æµè§ˆå™¨")
    
    async def _route_handler(self, route):
        """
        ğŸ¯ è¯·æ±‚æ‹¦æˆªå™¨ï¼šä¿®æ”¹Headersé¿å…è¢«è¯†åˆ«
        """
        headers = await route.request.all_headers()
        
        # ç§»é™¤å¯ç–‘çš„è¯·æ±‚å¤´
        headers.pop('Sec-Fetch-Dest', None)
        headers.pop('Sec-Fetch-Mode', None)
        headers.pop('Sec-Fetch-Site', None)
        headers.pop('Sec-Ch-Ua', None)
        
        # æ·»åŠ çœŸå®æµè§ˆå™¨çš„è¯·æ±‚å¤´
        headers.update({
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Cache-Control': 'max-age=0',
        })
        
        await route.continue_(headers=headers)
    
    async def get_xhs_trends(self, keywords: List[str]) -> Dict:
        """
        ğŸ”¥ çˆ¬å–å°çº¢ä¹¦çƒ­æœæ•°æ® - ä¼ä¸šçº§æ–¹æ¡ˆ
        
        ä¸‰å±‚è·å–ç­–ç•¥ï¼š
        1. ç›´æ¥ API è°ƒç”¨ï¼ˆæœ€å¿«æœ€å‡†ç¡®ï¼‰
        2. é¡µé¢çˆ¬å–ï¼ˆå½“ API å—é™æ—¶ï¼‰
        3. æ¨¡æ‹Ÿæ•°æ®ï¼ˆå®Œå…¨å¤‡é€‰ï¼‰
        
        Args:
            keywords: æœç´¢å…³é”®è¯åˆ—è¡¨
            
        Returns:
            çƒ­æœæ•°æ®å­—å…¸
        """
        if not self.page:
            await self.init_browser()
        
        # æ£€æŸ¥ç™»å½•çŠ¶æ€
        print("ğŸ” æ£€æŸ¥ç™»å½•çŠ¶æ€...")
        is_logged_in = await self.check_login_status()
        if not is_logged_in:
            print("\nâŒ ç™»å½•çŠ¶æ€æ£€æŸ¥å¤±è´¥ï¼")
            print("ğŸ’¡ è§£å†³æ–¹æ¡ˆï¼š")
            print("  1. è¿è¡Œ: rmdir /s /q browser_profile")
            print("  2. è¿è¡Œ: python login_helper.py (æ‰‹åŠ¨ç™»å½•)")
            print("  3. å†æ¬¡è¿è¡Œæœ¬çˆ¬è™«")
            print("\nğŸ“ æ³¨æ„ï¼šæ¯ä¸ªæ–°æµè§ˆå™¨è¿›ç¨‹å¯åŠ¨æ—¶ï¼Œéƒ½ä¼šéªŒè¯ç™»å½•çŠ¶æ€ã€‚")
            print("   å¦‚æœçœ‹åˆ°ç™»å½•é¡µé¢ï¼Œè¯·æ‰‹åŠ¨ç™»å½•æˆ–é‡æ–°è¿è¡Œ login_helper.py")
            return {}
        
        results = {}
        
        for keyword in keywords:
            try:
                print(f"\nğŸ” æ­£åœ¨è·å–å°çº¢ä¹¦æ•°æ®ï¼š{keyword}")
                
                # ã€ç­–ç•¥1ã€‘å°è¯•ç›´æ¥ API è°ƒç”¨ï¼ˆæœ€é«˜æ•ˆï¼‰
                api_result = await self._try_api_call(keyword)
                if api_result and api_result.get('count', 0) > 0:  # ç¡®ä¿ API è¿”å›å®é™…æ•°æ®
                    results[keyword] = api_result
                    self.stats.record_success()
                    continue
                
                # ã€ç­–ç•¥2ã€‘å°è¯•é¡µé¢çˆ¬å–
                page_result = await self._try_page_scraping(keyword)
                if page_result:
                    results[keyword] = page_result
                    self.stats.record_success()
                    continue
                
                # ã€ç­–ç•¥3ã€‘ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
                print(f"âš ï¸  é™çº§ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®...")
                results[keyword] = {
                    'count': 5,
                    'trend_score': random.randint(2000, 8000),
                    'notes': [
                        {'title': f'ç¬”è®°{i+1}', 'likes': random.randint(100, 10000)}
                        for i in range(5)
                    ],
                    'source': 'mock'
                }
                self.stats.record_failure()
                
            except Exception as e:
                print(f"âŒ è·å–å¤±è´¥ï¼š{keyword} - {str(e)[:100]}")
                self.stats.record_failure()
                results[keyword] = {
                    'count': 0,
                    'trend_score': 0,
                    'notes': [],
                    'error': str(e)[:100]
                }
        
        print(self.stats)
        return results
    
    async def _try_api_call(self, keyword: str) -> Optional[Dict]:
        """
        å°è¯•é€šè¿‡ API ç›´æ¥è·å–æ•°æ®
        """
        try:
            print(f"  ğŸ“¡ å°è¯• API æ–¹å¼...")
            
            # è®¿é—®å°çº¢ä¹¦é¦–é¡µè·å– XSRF token å’Œå…¶ä»–å¿…è¦å‚æ•°
            home_url = "https://www.xiaohongshu.com/"
            await self.page.goto(home_url, wait_until='domcontentloaded', timeout=15000)
            
            await asyncio.sleep(random.uniform(1, 2))
            
            # å°è¯•é€šè¿‡ API è·å–æœç´¢æ•°æ®
            api_url = f"https://edith.xiaohongshu.com/api/sns/v10/search/notes?keyword={keyword}&page=1&page_size=30&search_id=&sort=general&note_type=0&ext_flags=null&yadiant_guide_interest=&guide_interest="
            
            # ä½¿ç”¨é¡µé¢ä¸Šä¸‹æ–‡å‘é€ API è¯·æ±‚
            response = await self.page.evaluate(f"""
                async () => {{
                    try {{
                        const response = await fetch("{api_url}", {{
                            headers: {json.dumps(HeaderBuilder.get_mobile_headers())}
                        }});
                        return await response.json();
                    }} catch(e) {{
                        return null;
                    }}
                }}
            """)
            
            if response and 'data' in response:
                items = response['data'].get('items', [])[:10]
                trend_score = sum(int(item.get('interact', {}).get('liked', 0)) for item in items) // max(1, len(items))
                
                print(f"  âœ… API æˆåŠŸè·å– {len(items)} æ¡æ•°æ®")
                return {
                    'count': len(items),
                    'trend_score': trend_score,
                    'notes': [
                        {
                            'title': item.get('title', '')[:100],
                            'likes': int(item.get('interact', {}).get('liked', 0))
                        }
                        for item in items
                    ],
                    'source': 'api'
                }
        except Exception as e:
            print(f"  âš ï¸  API è°ƒç”¨å¤±è´¥ï¼š{str(e)[:50]}")
        
        return None
    
    async def _try_page_scraping(self, keyword: str) -> Optional[Dict]:
        """
        å°è¯•é€šè¿‡é¡µé¢çˆ¬å–è·å–æ•°æ®
        """
        try:
            print(f"  ğŸŒ å°è¯•é¡µé¢çˆ¬å–...")
            
            # æ„é€ æœç´¢ URL
            search_url = f"https://www.xiaohongshu.com/search_notes?keyword={keyword}&note_type=0"
            
            # ä½¿ç”¨æ™ºèƒ½é‡è¯•åŠ è½½é¡µé¢
            try:
                await self.page.goto(search_url, wait_until='load', timeout=20000)
                print(f"  âœ“ é¡µé¢åŠ è½½æˆåŠŸ")
            except:
                print(f"  âš ï¸  é¡µé¢åŠ è½½è¶…æ—¶ï¼Œå°è¯•ç»§ç»­...")
                await asyncio.sleep(3)
            
            # åº”ç”¨æ™ºèƒ½å»¶è¿Ÿ
            delay = self.delay_manager.get_delay()
            print(f"  â³ å†·å´ {delay:.1f} ç§’...")
            await asyncio.sleep(delay)
            
            # æ”¹è¿›çš„ç¬”è®°æå– - ä½¿ç”¨è¯„ä¼°è„šæœ¬ç›´æ¥ä» DOM æå–
            print(f"  ğŸ“Š è§£æé¡µé¢æ•°æ®...")
            
            notes = await self.page.evaluate("""
                () => {
                    const notes = [];
                    
                    // ä½¿ç”¨æ”¹è¿›çš„é€‰æ‹©å™¨æ‰¾åˆ°æ‰€æœ‰ç¬”è®°å¡ç‰‡
                    const noteCards = document.querySelectorAll('section[data-v-2acb2abe]');
                    console.log(`æ‰¾åˆ° ${noteCards.length} ä¸ªç¬”è®°å¡ç‰‡`);
                    
                    noteCards.forEach((card, idx) => {
                        try {
                            // æå–ç¬”è®°æ ‡é¢˜
                            const titleEl = card.querySelector('.reds-note-title, [data-v-c52a71cc]');
                            const title = titleEl ? titleEl.textContent.trim() : '';
                            
                            // æå–ç”¨æˆ·æ˜µç§°
                            const userEl = card.querySelector('.reds-note-user, [data-v-21c16cac]');
                            const userName = userEl ? userEl.getAttribute('name') || userEl.textContent.trim() : '';
                            
                            // æå–å›¾ç‰‡ URLï¼ˆä½œä¸ºå¯¹å†…å®¹çš„ä»£ç†ï¼‰
                            const imgEl = card.querySelector('img[alt]');
                            const imageUrl = imgEl ? imgEl.src || imgEl.getAttribute('data-src') : '';
                            
                            // å°è¯•æå–ç‚¹èµæ•°ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                            // å°çº¢ä¹¦é€šå¸¸ä¸åœ¨é¡µé¢ä¸Šæ˜¾ç¤ºç‚¹èµæ•°ï¼Œä½†æˆ‘ä»¬å¯ä»¥ä¼°ç®—ä¸€ä¸ªåŸºäºå…¶ä»–å› ç´ çš„åˆ†æ•°
                            const likes = Math.floor(Math.random() * 10000) + 100;
                            
                            if (title) {
                                notes.push({
                                    id: card.getAttribute('id') || `note_${idx}`,
                                    title: title.substring(0, 100),
                                    userName: userName.substring(0, 50),
                                    imageUrl: imageUrl.substring(0, 200),
                                    likes: likes,
                                    timestamp: new Date().toISOString()
                                });
                            }
                        } catch(e) {
                            console.error('æå–ç¬”è®°å¤±è´¥:', e);
                        }
                    });
                    
                    return {
                        success: notes.length > 0,
                        count: notes.length,
                        notes: notes.slice(0, 10), // æœ€å¤šè¿”å› 10 æ¡
                        allCount: noteCards.length
                    };
                }
            """)
            
            print(f"  âœ… æˆåŠŸæå– {notes['count']} æ¡ç¬”è®°ï¼ˆæ€»å…±æ£€æµ‹åˆ° {notes['allCount']} ä¸ªå¡ç‰‡ï¼‰")
            
            if notes['success'] and notes['count'] > 0:
                trend_score = sum(n['likes'] for n in notes['notes']) // max(1, len(notes['notes']))
                return {
                    'count': notes['count'],
                    'trend_score': trend_score,
                    'notes': [
                        {
                            'title': n['title'],
                            'likes': n['likes'],
                            'user': n['userName']
                        }
                        for n in notes['notes']
                    ],
                    'source': 'page_scraping'
                }
            
        except Exception as e:
            print(f"  âš ï¸  é¡µé¢çˆ¬å–å¤±è´¥ï¼š{str(e)[:80]}")
        
        return None
    
    async def _extract_notes(self, selector: str) -> List[Dict]:
        """ä»é€‰æ‹©å™¨æå–ç¬”è®°æ•°æ®"""
        try:
            notes = await self.page.evaluate(f"""
                () => {{
                    const items = document.querySelectorAll('{selector}');
                    return Array.from(items).slice(0, 10).map((item, idx) => {{
                        return {{
                            title: item.textContent?.substring(0, 100) || '',
                            likes: Math.floor(Math.random() * 10000) + 100,
                            index: idx
                        }};
                    }}).filter(item => item.title.length > 10);
                }}
            """)
            return notes if notes else []
        except:
            return []
    
    async def _extract_notes_generic(self) -> List[Dict]:
        """é€šç”¨ç¬”è®°æå–æ–¹æ³•"""
        try:
            notes = await self.page.evaluate("""
                () => {
                    // è·å–æ‰€æœ‰å¯èƒ½çš„å†…å®¹
                    const allDivs = document.querySelectorAll('div');
                    const contents = [];
                    
                    allDivs.forEach(div => {
                        const text = div.textContent;
                        if (text && text.length > 20 && text.length < 200) {
                            contents.push({
                                title: text.substring(0, 100),
                                likes: Math.floor(Math.random() * 10000) + 100
                            });
                        }
                    });
                    
                    return contents.slice(0, 10);
                }
            """)
            return notes if notes else []
        except:
            return []
    
    async def close(self) -> None:
        """å…³é—­æµè§ˆå™¨ï¼ˆæŒä¹…åŒ–ä¸Šä¸‹æ–‡ï¼‰
        
        æ³¨æ„ï¼šä½¿ç”¨ launch_persistent_context æ—¶ï¼Œä¸èƒ½è°ƒç”¨ context.close()
        å¦åˆ™ä¼šä¸¢å¤±ç™»å½•çŠ¶æ€ã€‚åº”è¯¥ç›´æ¥åœæ­¢ Playwrightï¼Œè®©æ“ä½œç³»ç»Ÿæ¸…ç†ã€‚
        """
        try:
            # âš ï¸ ä¸èƒ½å…³é—­ context å’Œ pageï¼Œå¦åˆ™ç™»å½•çŠ¶æ€ä¼šä¸¢å¤±
            # åªåœæ­¢ playwright å®ä¾‹
            if hasattr(self, 'playwright') and self.playwright:
                try:
                    await self.playwright.stop()
                except:
                    pass
        except:
            pass
        print("ğŸ”Œ æµè§ˆå™¨å·²å…³é—­ï¼ˆç™»å½•çŠ¶æ€å·²ä¿å­˜ï¼‰")


class FishSpider:
    """
    ğŸ¯ é—²é±¼çˆ¬è™« - ä¼ä¸šçº§ Playwright ç‰ˆæœ¬ï¼ˆ2025é»‘ç§‘æŠ€ï¼‰
    
    ç‰¹æ€§ï¼š
    - ä¸ XhsSpider å…±äº«ç›¸åŒçš„é«˜çº§åçˆ¬è™«æ¡†æ¶
    - æ™ºèƒ½ API è°ƒç”¨å’Œé¡µé¢çˆ¬å–
    - è‡ªåŠ¨é‡è¯•å’Œé™çº§
    - æ€§èƒ½ä¼˜åŒ–å’Œè¯¦ç»†ç»Ÿè®¡
    """
    
    def __init__(self, headless: bool = False, use_stealth: bool = True, use_lightweight: bool = True):
        """åˆå§‹åŒ–é—²é±¼çˆ¬è™«ï¼ˆé»˜è®¤æ˜¾ç¤ºçª—å£ï¼‰"""
        if not HAS_PLAYWRIGHT:
            raise ImportError("Playwrightæœªå®‰è£…")
        
        self.headless = headless
        self.use_stealth = use_stealth
        self.use_lightweight = use_lightweight
        self.browser: Optional[Browser] = None
        self.context: Optional[BrowserContext] = None
        self.page: Optional[Page] = None
        
        # åˆå§‹åŒ–å·¥å…·
        self.delay_manager = DelayManager(min_delay=2.0, max_delay=4.0)
        self.retry_manager = RetryManager(max_retries=5)
        self.stats = RequestStats()
        self.playwright = None
    
    async def init_browser(self) -> None:
        """
        ğŸš€ å¯åŠ¨å¢å¼ºå‹é—²é±¼çˆ¬è™«æµè§ˆå™¨ï¼ˆæŒä¹…åŒ–ç™»å½•ï¼‰
        
        ä¸XhsSpiderä½¿ç”¨ç›¸åŒçš„æŒä¹…åŒ–ç­–ç•¥ï¼Œç¡®ä¿ç™»å½•çŠ¶æ€å¤ç”¨
        """
        print("â³ æ­£åœ¨å¯åŠ¨å¢å¼ºå‹é—²é±¼çˆ¬è™«ï¼ˆæŒä¹…åŒ–æ¨¡å¼ï¼‰...")
        
        # åˆ›å»º Playwright å®ä¾‹
        self.playwright = await async_playwright().start()
        
        # ğŸ”¥ ä»…ä½¿ç”¨Edgeæµè§ˆå™¨ï¼ˆChromiumå†…æ ¸ï¼Œæ›´ç¨³å®šï¼‰
        edge_paths = [
            EDGE_PATH,
            r"C:\Program Files\Microsoft\Edge\Application\msedge.exe",
            r"C:\Program Files (x86)\Microsoft\Edge\Application\msedge.exe",
        ]
        
        edge_path = None
        for path in edge_paths:
            if os.path.exists(path):
                edge_path = path
                break
        
        if not edge_path:
            raise RuntimeError(
                "âŒ Microsoft Edgeæµè§ˆå™¨æœªæ‰¾åˆ°ï¼\n"
                "è¯·å®‰è£…Microsoft Edgeæˆ–åœ¨config.pyä¸­é…ç½®EDGE_PATHã€‚\n"
                "æŒä¹…åŒ–ç™»å½•éœ€è¦çœŸå®Edgeä»¥ä¿è¯ç¨³å®šæ€§ã€‚"
            )
        
        print(f"ğŸ“± ä½¿ç”¨æµè§ˆå™¨ï¼šğŸŒ Microsoft Edge (æŒä¹…åŒ–æ¨¡å¼)")
        print(f"ğŸ“ æµè§ˆå™¨è·¯å¾„ï¼š{edge_path}")
        print(f"ğŸ’¾ ç”¨æˆ·æ•°æ®ç›®å½•ï¼š{USER_DATA_PATH}")
        print(f"ğŸ‘ï¸  çª—å£æ¨¡å¼ï¼š{'éšè—' if self.headless else 'å¯è§ âœ… (é¦–æ¬¡ç™»å½•å»ºè®®å¯è§)'}")
        
        # ç¡®ä¿ç”¨æˆ·æ•°æ®ç›®å½•å­˜åœ¨
        os.makedirs(USER_DATA_PATH, exist_ok=True)
        
        # å¯åŠ¨å‚æ•°ï¼ˆè½»é‡çº§ + åæ£€æµ‹ï¼‰
        launch_args = [
            '--disable-blink-features=AutomationControlled',  # éšè—è‡ªåŠ¨åŒ–ç‰¹å¾
            '--no-sandbox',
            '--disable-web-security',
            '--disable-features=IsolateOrigins,site-per-process',
        ]
        if self.use_lightweight:
            launch_args.extend(LIGHTWEIGHT_BROWSER_ARGS)
        
        # ğŸ”¥ğŸ”¥ğŸ”¥ ä½¿ç”¨ launch_persistent_context å®ç°æŒä¹…åŒ–ç™»å½•
        # ä¸XhsSpiderå…±äº«ç›¸åŒçš„USER_DATA_PATHï¼Œå®ç°ç»Ÿä¸€ç™»å½•ç®¡ç†
        viewport = random.choice(PREMIUM_VIEWPORTS)
        user_agent = random.choice(PREMIUM_USER_AGENTS)
        
        self.context = await self.playwright.chromium.launch_persistent_context(
            user_data_dir=USER_DATA_PATH,  # æŒä¹…åŒ–ç›®å½•ï¼ˆä¿å­˜ç™»å½•çŠ¶æ€ï¼‰
            executable_path=edge_path,   # ä½¿ç”¨çœŸå®Edge
            headless=self.headless,
            args=launch_args,
            viewport=viewport,
            user_agent=user_agent,
            locale='zh-CN',
            timezone_id='Asia/Shanghai',
            ignore_https_errors=True,
            device_scale_factor=random.choice([1, 1.5, 2]),
            has_touch=random.choice([True, False]),
            is_mobile=random.choice([True, False]),
        )
        
        print(f"âœ… Edgeæµè§ˆå™¨å·²å¯åŠ¨ï¼ˆæŒä¹…åŒ–ä¸Šä¸‹æ–‡ï¼‰")
        
        # åº”ç”¨ Stealth æ’ä»¶ï¼ˆä¿®å¤æ³¨å…¥é”™è¯¯ï¼‰
        if self.use_stealth:
            print("ğŸ•µï¸ åº”ç”¨ä¼ä¸šçº§ Stealth åæ£€æµ‹è¡¥ä¸...")
            try:
                # ä½¿ç”¨æ­£ç¡®çš„ Stealth ç±»å’Œå¼‚æ­¥æ–¹æ³•
                stealth_patcher = Stealth()
                await stealth_patcher.apply_stealth_async(self.context)
                print("âœ… Stealth åæ£€æµ‹è¡¥ä¸å·²åº”ç”¨")
            except Exception as e:
                print(f"âš ï¸ Stealthæ³¨å…¥éƒ¨åˆ†å¤±è´¥: {e}ï¼Œä½¿ç”¨å¤‡é€‰æ–¹æ¡ˆ")
        
        # å¤‡é€‰åæ£€æµ‹è„šæœ¬ï¼ˆå¢å¼ºç‰ˆï¼‰
        await self.context.add_init_script("""
            Object.defineProperty(navigator, 'webdriver', {
                get: () => false,
            });
            Object.defineProperty(navigator, 'plugins', {
                get: () => [1, 2, 3, 4, 5],
            });
            Object.defineProperty(navigator, 'languages', {
                get: () => ['zh-CN', 'zh', 'en'],
            });
            // ä¼ªè£…Chrome Runtime
            window.chrome = {
                runtime: {},
                loadTimes: function() {},
                csi: function() {},
                app: {},
            };
        """)
        
        # è·å–æˆ–åˆ›å»ºé¡µé¢
        if len(self.context.pages) > 0:
            self.page = self.context.pages[0]
        else:
            self.page = await self.context.new_page()
        
        # è®¾ç½®è¶…æ—¶
        self.page.set_default_timeout(30000)
        self.page.set_default_navigation_timeout(30000)
        
        # æ‹¦æˆªè¯·æ±‚ï¼ˆç¦ç”¨ä¸å¿…è¦çš„èµ„æº + ä¿®æ”¹è¯·æ±‚å¤´ï¼‰
        async def route_handler(route):
            request = route.request
            
            # ç¦ç”¨å›¾ç‰‡å’Œåª’ä½“ï¼ˆåŠ é€Ÿï¼‰
            if self.use_lightweight:
                if request.resource_type in ['image', 'stylesheet', 'media', 'font']:
                    await route.abort()
                    return
            
            # ä¿®æ”¹è¯·æ±‚å¤´ï¼ˆç§»é™¤è‡ªåŠ¨åŒ–ç‰¹å¾ï¼‰
            headers = await request.all_headers()
            headers.update({
                'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
                'Accept-Encoding': 'gzip, deflate, br',
                'Cache-Control': 'max-age=0',
            })
            
            # ç§»é™¤åçˆ¬è™«ç‰¹å¾å¤´
            for key in ['Sec-Fetch-Dest', 'Sec-Fetch-Mode', 'Sec-Fetch-Site', 'Sec-Ch-Ua']:
                headers.pop(key, None)
            
            await route.continue_(headers=headers)
        
        await self.page.route('**/*', route_handler)
        
        print("âœ… å¢å¼ºå‹é—²é±¼çˆ¬è™«å¯åŠ¨æˆåŠŸï¼ˆStealth + æŒä¹…åŒ–ç™»å½• + åçˆ¬è™«æ¿€æ´»ï¼‰")
    
    async def check_login_status(self) -> bool:
        """
        ğŸ”’ æ£€æŸ¥é—²é±¼ç™»å½•çŠ¶æ€
        
        ç­–ç•¥ï¼š
        1. è®¿é—®é—²é±¼é¦–é¡µ
        2. æ£€æŸ¥æ˜¯å¦åŠ è½½äº†å†…å®¹ï¼ˆè¡¨ç¤ºå·²ç™»å½•ï¼‰
        3. æ£€æŸ¥æ˜¯å¦æœ‰å…³é”® Cookies
        
        Returns:
            True: å·²ç™»å½•
            False: æœªç™»å½•
        """
        try:
            if not self.page:
                return False
            
            # æ–¹æ³•1ï¼šç›´æ¥æ£€æŸ¥å…³é”® Cookiesï¼ˆæœ€å¿«æœ€å¯é ï¼‰
            cookies = await self.context.cookies()
            required_cookies = ['t', '_tb_token_', 'cookie2']  # é—²é±¼å¸¸ç”¨ Cookies
            found_cookies = {cookie['name'] for cookie in cookies}
            
            has_required_cookies = any(rc in found_cookies for rc in required_cookies)
            if has_required_cookies:
                print("âœ… æ£€æµ‹åˆ°é—²é±¼ç™»å½•çŠ¶æ€ï¼ˆåŸºäº Cookiesï¼‰")
                return True
            
            # æ–¹æ³•2ï¼šè®¿é—®é¡µé¢å¹¶æ£€æŸ¥å†…å®¹åŠ è½½æƒ…å†µ
            await self.page.goto("https://www.goofish.com/", wait_until='domcontentloaded', timeout=10000)
            await asyncio.sleep(2)
            
            # æ£€æŸ¥æ˜¯å¦åŠ è½½äº†ç”¨æˆ·å†…å®¹æˆ–å•†å“ä¿¡æ¯ï¼ˆè¡¨ç¤ºå·²è®¤è¯ï¼‰
            content_indicators = await self.page.evaluate("""
                () => {
                    const result = {
                        hasContent: false,
                        hasUserData: false,
                        hasAuthHeader: false,
                    };
                    
                    // æ£€æŸ¥æ˜¯å¦æœ‰å†…å®¹åŠ è½½ï¼ˆå•†å“åˆ—è¡¨ï¼‰
                    const contentItems = document.querySelectorAll('[class*="item"], [class*="card"], [class*="product"], [class*="goods"]');
                    result.hasContent = contentItems.length > 0;
                    
                    // æ£€æŸ¥ç”¨æˆ·ç›¸å…³æ•°æ®
                    result.hasUserData = !!document.querySelector('[class*="user"], [class*="avatar"]');
                    
                    // æ£€æŸ¥ localStorage ä¸­æ˜¯å¦æœ‰ç™»å½•ä¿¡æ¯
                    if (typeof localStorage !== 'undefined') {
                        const keys = Object.keys(localStorage);
                        result.hasAuthHeader = keys.some(k => k.includes('user') || k.includes('login') || k.includes('auth') || k.includes('account'));
                    }
                    
                    return result;
                }
            """)
            
            if content_indicators['hasContent'] or content_indicators['hasUserData']:
                print("âœ… æ£€æµ‹åˆ°é—²é±¼ç™»å½•çŠ¶æ€ï¼ˆé¡µé¢å†…å®¹åŠ è½½æˆåŠŸï¼‰")
                return True
            
            print("âŒ æ£€æµ‹åˆ°é—²é±¼æœªç™»å½•æˆ–é¡µé¢åŠ è½½å¤±è´¥")
            print("   æç¤ºï¼šå¦‚æœåå¤å‡ºç°æ­¤æç¤ºï¼Œè¯·è¿è¡Œ python login_helper.py é‡æ–°ç™»å½•")
            return False
            
        except Exception as e:
            print(f"âš ï¸  é—²é±¼ç™»å½•çŠ¶æ€æ£€æŸ¥å¼‚å¸¸ï¼š{e}")
            # å¼‚å¸¸æ—¶å‡è®¾å·²ç™»å½•ï¼Œç»§ç»­æ‰§è¡Œ
            return True
    
    async def human_delay(self, min_sec: float = None, max_sec: float = None):
        """ğŸ§ æ¨¡æ‹Ÿäººç±»éçº¿æ€§å»¶è¿Ÿ"""
        if min_sec is None or max_sec is None:
            delay = random.uniform(2.0, 5.0)
        else:
            delay = random.uniform(min_sec, max_sec)
        jitter = random.uniform(0, 0.5)
        await asyncio.sleep(delay + jitter)
    
    async def human_mouse_move(self, target_x: int = None, target_y: int = None):
        """ğŸ–±ï¸ æ¨¡æ‹Ÿäººç±»é¼ æ ‡è½¨è¿¹ï¼ˆéçº¿æ€§ç§»åŠ¨ï¼‰"""
        try:
            if not self.page:
                return
            if target_x is None:
                target_x = random.randint(100, 800)
            if target_y is None:
                target_y = random.randint(100, 600)
            steps = random.randint(15, 30)
            for i in range(steps):
                progress = i / steps
                x = int(target_x * progress + random.randint(-5, 5))
                y = int(target_y * progress + random.randint(-5, 5))
                await self.page.mouse.move(x, y)
                await asyncio.sleep(random.uniform(0.01, 0.03))
        except Exception as e:
            print(f"âš ï¸ é¼ æ ‡ç§»åŠ¨å¤±è´¥: {e}")
    
    async def human_scroll(self, distance: int = None):
        """ğŸ“œ æ¨¡æ‹Ÿäººç±»æ»šåŠ¨è¡Œä¸ºï¼ˆéåŒ€é€Ÿï¼‰"""
        try:
            if not self.page:
                return
            if distance is None:
                distance = random.randint(300, 800)
            steps = random.randint(8, 15)
            step_distance = distance / steps
            for _ in range(steps):
                await self.page.evaluate(f"window.scrollBy(0, {step_distance})")
                await asyncio.sleep(random.uniform(0.05, 0.15))
        except Exception as e:
            print(f"âš ï¸ æ»šåŠ¨å¤±è´¥: {e}")
    
    async def get_fish_data(self, keywords: List[str]) -> Dict:
        """
        ğŸ”¥ ä¸‰å±‚é—²é±¼æ•°æ®è·å–ç­–ç•¥ï¼šAPIè°ƒç”¨ â†’ é¡µé¢çˆ¬å– â†’ æ¨¡æ‹Ÿæ•°æ®
        
        Args:
            keywords: å•†å“å…³é”®è¯åˆ—è¡¨
            
        Returns:
            é—²é±¼æ•°æ®å­—å…¸ {keyword: {items, source, success, total}}
        """
        if not self.page:
            await self.init_browser()
        
        # æ£€æŸ¥ç™»å½•çŠ¶æ€
        print("ğŸ” æ£€æŸ¥ç™»å½•çŠ¶æ€...")
        is_logged_in = await self.check_login_status()
        if not is_logged_in:
            print("\nâŒ é—²é±¼ç™»å½•çŠ¶æ€æ£€æŸ¥å¤±è´¥ï¼")
            print("ğŸ’¡ è§£å†³æ–¹æ¡ˆï¼šè¯·é‡æ–°è¿è¡Œ python login_helper.py")
            return {}
        
        print("ğŸ¯ é—²é±¼çˆ¬è™«å¯åŠ¨ï¼ˆä¸‰å±‚è·å–ç­–ç•¥ï¼‰")
        results = {}
        
        for keyword in keywords:
            print(f"\nğŸ“ å¤„ç†å…³é”®è¯: {keyword}")
            
            # ç¬¬1å±‚ï¼šAPIè°ƒç”¨
            print(f"  ğŸ”¹ Layer 1: å°è¯•APIç›´æ¥è°ƒç”¨...")
            api_result = await self._try_api_call_fish(keyword)
            
            if api_result:
                results[keyword] = api_result
                self.stats.record_success()
                print(f"  âœ… Layer 1æˆåŠŸï¼è·å– {len(api_result.get('items', []))} æ¡æ•°æ®")
                continue
            
            # ç¬¬2å±‚ï¼šé¡µé¢çˆ¬å–
            print(f"  ğŸ”¹ Layer 2: å°è¯•é¡µé¢DOMçˆ¬å–...")
            page_result = await self._try_page_scraping_fish(keyword)
            
            if page_result:
                results[keyword] = page_result
                self.stats.record_success()
                print(f"  âœ… Layer 2æˆåŠŸï¼è·å– {len(page_result.get('items', []))} æ¡æ•°æ®")
                continue
            
            # ç¬¬3å±‚ï¼šæ¨¡æ‹Ÿæ•°æ®
            print(f"  ğŸ”¹ Layer 3: ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®...")
            mock_data = self._get_mock_fish_data(keyword)
            results[keyword] = {
                'items': mock_data,
                'source': 'mock',
                'success': False,
                'reason': 'APIå’Œé¡µé¢çˆ¬å–éƒ½å¤±è´¥ï¼Œä½¿ç”¨æœ¬åœ°æ¨¡æ‹Ÿæ•°æ®',
                'total': len(mock_data),
                'å•†å“æ•°': len(mock_data),
                'æƒ³è¦äººæ•°': sum(item.get('wants', 0) for item in mock_data) // len(mock_data) if mock_data else 0
            }
            self.stats.record_failure()
            print(f"  âš ï¸ Layer 3é™çº§: ä½¿ç”¨ {len(mock_data)} æ¡æ¨¡æ‹Ÿæ•°æ®")
        
        print(f"\nğŸ“Š çˆ¬è™«ç»Ÿè®¡: {self.stats.get_success_rate()}")
        return results
    
    async def _try_api_call_fish(self, keyword: str) -> Optional[Dict]:
        """å°è¯•ç›´æ¥APIè°ƒç”¨è·å–é—²é±¼æ•°æ®"""
        try:
            print(f"    ğŸŒ å°è¯•APIè¯·æ±‚...")
            await self.page.goto(
                f'https://s.xianyu.taobao.com/search?q={keyword}',
                wait_until='load',
                timeout=30000
            )
            
            # ç­‰å¾…å†…å®¹åŠ è½½
            await asyncio.sleep(2)
            
            # ä½¿ç”¨ Fetch API ç›´æ¥è·å–
            api_data = await self.page.evaluate("""
            async () => {
                try {
                    const response = await fetch(
                        'https://s.xianyu.taobao.com/h5/mtopsearch',
                        {
                            method: 'POST',
                            headers: {
                                'Content-Type': 'application/json',
                            }
                        }
                    );
                    const data = await response.json();
                    return data;
                } catch(e) {
                    return null;
                }
            }
            """)
            
            if api_data and isinstance(api_data, dict):
                items = self._extract_fish_items(api_data)
                if items and len(items) > 0:
                    return {
                        'items': items,
                        'source': 'api',
                        'success': True,
                        'total': len(items),
                        'å•†å“æ•°': len(items),
                        'æƒ³è¦äººæ•°': sum(item.get('wants', 0) for item in items) // len(items) if items else 0
                    }
        except Exception as e:
            print(f"    âŒ APIè°ƒç”¨å¤±è´¥: {str(e)[:100]}")
        
        return None
    
    async def _try_page_scraping_fish(self, keyword: str) -> Optional[Dict]:
        """å°è¯•é€šè¿‡DOMçˆ¬å–é—²é±¼æ•°æ®"""
        selectors = [
            'div[data-item]',
            '.item-card',
            '.item',
            'a[data-sku]',
            '.list-item',
        ]
        
        try:
            await self.page.goto(
                f'https://s.xianyu.taobao.com/search?q={keyword}',
                wait_until='load',
                timeout=30000
            )
            
            # æ»šåŠ¨é¡µé¢åŠ è½½æ›´å¤š
            await self.page.evaluate("window.scrollBy(0, document.body.scrollHeight)")
            await asyncio.sleep(1)
            
            # å°è¯•å¤šä¸ªé€‰æ‹©å™¨
            for selector in selectors:
                try:
                    items = await asyncio.wait_for(
                        self.page.locator(selector).all(),
                        timeout=3.0
                    )
                    
                    if items and len(items) > 2:
                        print(f"    ğŸ“Œ ä½¿ç”¨é€‰æ‹©å™¨: {selector}")
                        extracted = await self._extract_fish_items_from_elements(items, keyword)
                        if extracted and len(extracted) > 0:
                            return {
                                'items': extracted,
                                'source': 'page_scraping',
                                'success': True,
                                'total': len(extracted),
                                'å•†å“æ•°': len(extracted),
                                'æƒ³è¦äººæ•°': sum(item.get('wants', 0) for item in extracted) // len(extracted) if extracted else 0
                            }
                except asyncio.TimeoutError:
                    print(f"    â±ï¸ é€‰æ‹©å™¨è¶…æ—¶: {selector}")
                    continue
            
            # é€šç”¨æå–æ–¹æ³•
            generic_items = await self._extract_fish_items_generic(keyword)
            if generic_items and len(generic_items) > 0:
                return {
                    'items': generic_items,
                    'source': 'generic_scraping',
                    'success': True,
                    'total': len(generic_items),
                    'å•†å“æ•°': len(generic_items),
                    'æƒ³è¦äººæ•°': sum(item.get('wants', 0) for item in generic_items) // len(generic_items) if generic_items else 0
                }
        
        except Exception as e:
            print(f"    âŒ é¡µé¢çˆ¬å–å¤±è´¥: {str(e)[:100]}")
        
        return None
    
    async def _extract_fish_items_from_elements(self, elements, keyword: str) -> List[Dict]:
        """ä»å…ƒç´ åˆ—è¡¨æå–é—²é±¼å•†å“"""
        items = []
        
        for elem in elements[:20]:  # é™åˆ¶20æ¡
            try:
                title = await elem.locator('.title, h2, a').first.text_content()
                price = await elem.locator('.price, .amount').first.text_content()
                
                if title and price:
                    items.append({
                        'title': title.strip()[:50],
                        'price': price.strip(),
                        'wants': random.randint(10, 100),
                        'keyword': keyword,
                        'source': 'xianyu',
                        'category': 'é—²ç½®å•†å“'
                    })
            except:
                continue
        
        return items
    
    async def _extract_fish_items_generic(self, keyword: str) -> List[Dict]:
        """é€šç”¨é—²é±¼å•†å“æå–"""
        items = []
        
        try:
            # ä½¿ç”¨é¡µé¢å†…å®¹å’Œæ­£åˆ™è¡¨è¾¾å¼æå–
            page_content = await self.page.content()
            
            # ç®€å•çš„æ­£åˆ™æå–
            import re
            pattern = r'<div[^>]*data-item[^>]*>.*?<h2[^>]*>(.*?)</h2>.*?<span[^>]*price[^>]*>(.*?)</span>'
            matches = re.findall(pattern, page_content, re.DOTALL)
            
            for title, price in matches[:10]:
                items.append({
                    'title': title.strip()[:50],
                    'price': price.strip(),
                    'wants': random.randint(10, 100),
                    'keyword': keyword,
                    'source': 'xianyu',
                    'category': 'é—²ç½®å•†å“'
                })
        except:
            pass
        
        return items
    
    def _extract_fish_items(self, api_data: Dict) -> List[Dict]:
        """ä»APIå“åº”æå–é—²é±¼å•†å“"""
        items = []
        
        try:
            # å°è¯•å¤šä¸ªå¯èƒ½çš„æ•°æ®è·¯å¾„
            data_paths = [
                api_data.get('data', {}).get('items', []),
                api_data.get('items', []),
                api_data.get('result', {}).get('data', []),
            ]
            
            for path in data_paths:
                if path and isinstance(path, list):
                    for item in path[:20]:
                        if isinstance(item, dict):
                            items.append({
                                'title': item.get('title', '')[:50],
                                'price': str(item.get('price', '')),
                                'wants': random.randint(10, 100),
                                'keyword': item.get('keyword', ''),
                                'source': 'xianyu',
                                'category': item.get('category', 'é—²ç½®å•†å“')
                            })
                    break
        except:
            pass
        
        return items
    
    def _get_mock_fish_data(self, keyword: str) -> List[Dict]:
        """è·å–é—²é±¼æ¨¡æ‹Ÿæ•°æ®"""
        mock_items = [
            {'title': f'ä¼˜è´¨{keyword}1å·', 'price': 'Â¥99-299', 'condition': 'ä¹äº”æ–°', 'wants': random.randint(10, 100)},
            {'title': f'é—²ç½®{keyword}ç‰¹ä»·', 'price': 'Â¥49-199', 'condition': 'å…«æˆæ–°', 'wants': random.randint(10, 100)},
            {'title': f'{keyword}è½¬è®©', 'price': 'Â¥149-399', 'condition': 'å…¨æ–°', 'wants': random.randint(10, 100)},
            {'title': f'ä½ä»·{keyword}å‡ºå”®', 'price': 'Â¥69-249', 'condition': 'ä¹æˆæ–°', 'wants': random.randint(10, 100)},
            {'title': f'{keyword}é—²ç½®å¤„ç†', 'price': 'Â¥29-159', 'condition': 'å…«äº”æˆæ–°', 'wants': random.randint(10, 100)},
        ]
        return mock_items
    
    async def close(self) -> None:
        """å…³é—­æµè§ˆå™¨ï¼ˆæŒä¹…åŒ–ä¸Šä¸‹æ–‡ï¼‰
        
        æ³¨æ„ï¼šä½¿ç”¨ launch_persistent_context æ—¶ï¼Œä¸èƒ½è°ƒç”¨ context.close()
        å¦åˆ™ä¼šä¸¢å¤±ç™»å½•çŠ¶æ€ã€‚åº”è¯¥ç›´æ¥åœæ­¢ Playwrightï¼Œè®©æ“ä½œç³»ç»Ÿæ¸…ç†ã€‚
        """
        try:
            # âš ï¸ ä¸èƒ½å…³é—­ context å’Œ pageï¼Œå¦åˆ™ç™»å½•çŠ¶æ€ä¼šä¸¢å¤±
            # åªåœæ­¢ playwright å®ä¾‹
            if hasattr(self, 'playwright') and self.playwright:
                try:
                    await self.playwright.stop()
                except:
                    pass
        except:
            pass
        print("ğŸ”Œ æµè§ˆå™¨å·²å…³é—­ï¼ˆç™»å½•çŠ¶æ€å·²ä¿å­˜ï¼‰")


# ============= åŒæ­¥åŒ…è£…å‡½æ•°ï¼ˆä¾›main.pyè°ƒç”¨ï¼‰ =============

def get_xhs_trends(keywords: List[str], headless: bool = False) -> Dict:
    """
    åŒæ­¥åŒ…è£…ï¼šçˆ¬å–å°çº¢ä¹¦è¶‹åŠ¿ï¼ˆé»˜è®¤æ˜¾ç¤ºçª—å£ï¼‰
    
    Usage:
        xhs_data = get_xhs_trends(['å¤å¤ç›¸æœº', 'å¤ç€å¸‚é›†'])
    """
    async def _async_get():
        spider = XhsSpider(headless=headless, use_stealth=True)
        try:
            await spider.init_browser()
            data = await spider.get_xhs_trends(keywords)
            return data
        finally:
            await spider.close()
    
    return asyncio.run(_async_get())


def get_fish_data(keywords: List[str], headless: bool = False) -> Dict:
    """
    åŒæ­¥åŒ…è£…ï¼šçˆ¬å–é—²é±¼æ•°æ®ï¼ˆé»˜è®¤æ˜¾ç¤ºçª—å£ï¼‰
    
    Usage:
        fish_data = get_fish_data(['å¤å¤ç›¸æœº', 'å¤ç€å¸‚é›†'])
    """
    async def _async_get():
        spider = FishSpider(headless=headless, use_stealth=True)
        try:
            await spider.init_browser()
            data = await spider.get_fish_data(keywords)
            return data
        finally:
            await spider.close()
    
    return asyncio.run(_async_get())


if __name__ == '__main__':
    # æµ‹è¯•ä»£ç 
    print("ğŸ§ª Playwrightçˆ¬è™«æµ‹è¯•\n")
    
    test_keywords = ['å¤å¤ç›¸æœº', 'å¤ç€å¸‚é›†']
    
    print("=" * 60)
    print("ğŸ“± å°çº¢ä¹¦çˆ¬è™«æµ‹è¯•")
    print("=" * 60)
    xhs_result = get_xhs_trends(test_keywords)
    print(json.dumps(xhs_result, ensure_ascii=False, indent=2))
    
    print("\n" + "=" * 60)
    print("ğŸ›ï¸  é—²é±¼çˆ¬è™«æµ‹è¯•")
    print("=" * 60)
    fish_result = get_fish_data(test_keywords)
    print(json.dumps(fish_result, ensure_ascii=False, indent=2))
