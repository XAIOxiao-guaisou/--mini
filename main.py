"""
å…¨è‡ªåŠ¨è“æµ·èµ›é“æŒ–æ˜ä¸»ç¨‹åº
é›†æˆçˆ¬è™«ã€åˆ†æã€æ¨é€å…¨æµç¨‹
"""

import time
import random
import json
import logging
from datetime import datetime
from typing import List, Dict
from pathlib import Path

from scrapers.spider import get_xhs_trends, get_fish_data
from engine.analyzer import BlueOceanAnalyzer
from utils.logic import NichePushLogic
from config import (
    DELAY_BETWEEN_REQUESTS, 
    PUSH_INTERVAL,
    LOG_LEVEL,
    LOG_FILE,
    REPORT_FILE,
    ENABLE_WECOM_PUSH,
    MIN_POTENTIAL_SCORE,
    MAX_COMPETITION,
    XHS_DATA_FILE
)


# ==================== æ—¥å¿—é…ç½® ====================
logging.basicConfig(
    level=getattr(logging, LOG_LEVEL),
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(LOG_FILE),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


class NicheHunterEngine:
    """è“æµ·èµ›é“çŒäººå¼•æ“"""
    
    def __init__(self):
        """åˆå§‹åŒ–å¼•æ“"""
        self.pusher = NichePushLogic() if ENABLE_WECOM_PUSH else None
        self.results = []
        self.push_records = []
        
    def run_mission(
        self,
        top_trends_n: int = 15,
        top_results_n: int = 5,
        enable_push: bool = ENABLE_WECOM_PUSH
    ) -> Dict:
        """
        æ‰§è¡Œå®Œæ•´è“æµ·æŒ–æ˜ä»»åŠ¡
        
        æµç¨‹ï¼š
        1. ğŸ” æŠ“å–å°çº¢ä¹¦çƒ­æœè¯æ¡ï¼ˆå‰15ä¸ªï¼‰
        2. ğŸ›ï¸ æŸ¥è¯¢é—²é±¼æ•°æ®ï¼ˆæ¯ä¸ªè¯é—´éš”20-30ç§’ï¼‰
        3. ğŸ“Š è®¡ç®—è“æµ·æŒ‡æ•°å¹¶æ’åº
        4. ğŸ“¤ æ¨é€ç¬¦åˆæ¡ä»¶çš„è¯æ¡åˆ°ä¼ä¸šå¾®ä¿¡
        5. ğŸ’¾ ä¿å­˜åˆ†ææŠ¥å‘Š
        
        Args:
            top_trends_n: æŠ“å–çš„çƒ­æœè¯æ¡æ•°é‡
            top_results_n: è¿”å›çš„æœ€ä½³èµ›é“æ•°
            enable_push: æ˜¯å¦æ¨é€åˆ°ä¼ä¸šå¾®ä¿¡
            
        Returns:
            æ‰§è¡Œç»“æœå­—å…¸
        """
        
        print("\n" + "="*70)
        print("ğŸš€ å¯åŠ¨å…¨ç½‘è“æµ·èµ›é“æƒ…æŠ¥æ‰«æ")
        print("="*70)
        
        start_time = datetime.now()
        logger.info("ä»»åŠ¡å¼€å§‹")
        
        try:
            # 1ï¸âƒ£ ç¬¬ä¸€æ­¥ï¼šæŠ“å–å°çº¢ä¹¦çƒ­æœè¯æ¡
            print("\nã€ç¬¬1æ­¥ã€‘ğŸ” æŠ“å–å°çº¢ä¹¦çƒ­æœè¯æ¡...")
            keywords = self._fetch_xhs_trends(top_trends_n)
            
            if not keywords:
                logger.warning("æœªèƒ½æˆåŠŸè·å–çƒ­æœè¯æ¡")
                return {
                    'status': 'failed',
                    'message': 'æœªèƒ½è·å–çƒ­æœè¯æ¡',
                    'duration': str(datetime.now() - start_time)
                }
            
            print(f"âœ“ æˆåŠŸè·å– {len(keywords)} ä¸ªçƒ­æœè¯æ¡\n")
            
            # 2ï¸âƒ£ ç¬¬äºŒæ­¥ï¼šæŸ¥è¯¢é—²é±¼æ•°æ®å¹¶è®¡ç®—æŒ‡æ•°
            print("ã€ç¬¬2æ­¥ã€‘ğŸ›ï¸ æŸ¥è¯¢é—²é±¼æ•°æ®å¹¶è®¡ç®—è“æµ·æŒ‡æ•°...")
            self.results = self._analyze_keywords(keywords)
            
            if not self.results:
                logger.warning("æœªèƒ½åˆ†æä»»ä½•è¯æ¡")
                return {
                    'status': 'partial_failed',
                    'message': 'æ•°æ®åˆ†æå¤±è´¥',
                    'duration': str(datetime.now() - start_time)
                }
            
            # 3ï¸âƒ£ ç¬¬ä¸‰æ­¥ï¼šæ’åºå¹¶ç­›é€‰
            print("\nã€ç¬¬3æ­¥ã€‘ğŸ“Š ç­›é€‰ä¼˜è´¨è“æµ·è¯æ¡...")
            top_results = BlueOceanAnalyzer.rank_results(self.results, top_results_n)
            
            # è¿‡æ»¤ç¬¦åˆæ¨é€æ¡ä»¶çš„è¯æ¡
            qualified_results = [
                r for r in top_results 
                if BlueOceanAnalyzer.is_qualified(r['è“æµ·æŒ‡æ•°'], r['é—²é±¼å•†å“æ•°'])
            ]
            
            print(f"âœ“ å‘ç° {len(qualified_results)} ä¸ªä¼˜è´¨è“æµ·è¯æ¡")
            
            # æ‰“å°å‰5ä¸ªç»“æœ
            print("\n" + "-"*70)
            print("ğŸ† TOP 5 æ½œåŠ›èµ›é“")
            print("-"*70)
            for i, result in enumerate(top_results[:5], 1):
                self._print_result(i, result)
            
            # 4ï¸âƒ£ ç¬¬å››æ­¥ï¼šæ¨é€åˆ°ä¼ä¸šå¾®ä¿¡
            if enable_push and qualified_results:
                print("\nã€ç¬¬4æ­¥ã€‘ğŸ“¤ æ¨é€è“æµ·è¯æ¡åˆ°ä¼ä¸šå¾®ä¿¡...")
                self._push_results(qualified_results)
            
            # 5ï¸âƒ£ ç¬¬äº”æ­¥ï¼šä¿å­˜æŠ¥å‘Š
            print("\nã€ç¬¬5æ­¥ã€‘ğŸ’¾ ä¿å­˜åˆ†ææŠ¥å‘Š...")
            self._save_report(top_results)
            
            # è®¡ç®—æ‰§è¡Œæ—¶é—´
            duration = datetime.now() - start_time
            
            print("\n" + "="*70)
            print("âœ… ä»»åŠ¡å®Œæˆ")
            print("="*70)
            print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯ï¼š")
            print(f"  â€¢ å¤„ç†è¯æ¡ï¼š{len(self.results)} ä¸ª")
            print(f"  â€¢ ä¼˜è´¨è¯æ¡ï¼š{len(qualified_results)} ä¸ª")
            print(f"  â€¢ æ¨é€æˆåŠŸï¼š{len(self.push_records)} ä¸ª")
            print(f"  â€¢ æ‰§è¡Œè€—æ—¶ï¼š{duration}")
            
            logger.info(f"ä»»åŠ¡æˆåŠŸå®Œæˆï¼Œè€—æ—¶ {duration}")
            
            return {
                'status': 'success',
                'keywords_analyzed': len(self.results),
                'qualified_keywords': len(qualified_results),
                'push_count': len(self.push_records),
                'top_results': top_results,
                'duration': str(duration)
            }
        
        except Exception as e:
            logger.error(f"ä»»åŠ¡æ‰§è¡Œå‡ºé”™ï¼š{e}", exc_info=True)
            return {
                'status': 'error',
                'message': str(e),
                'duration': str(datetime.now() - start_time)
            }
    
    def _fetch_xhs_trends(self, top_n: int = 15) -> List[Dict]:
        """
        è·å–å°çº¢ä¹¦çƒ­æœè¯æ¡
        
        æµç¨‹ï¼š
        1. ä» xhs_data.json è¯»å–åˆå§‹å…³é”®è¯åˆ—è¡¨
        2. ä½¿ç”¨ Playwright çˆ¬è™«è·å–è¿™äº›å…³é”®è¯çš„çƒ­æœæ•°æ®
        3. è¿”å›å‰ N ä¸ªçƒ­æœè¯æ¡
        
        Args:
            top_n: è·å–å‰Nä¸ªçƒ­æœ
            
        Returns:
            çƒ­æœè¯æ¡åˆ—è¡¨
        """
        try:
            # æ­¥éª¤1ï¼šä» xhs_data.json è¯»å–åˆå§‹å…³é”®è¯
            print("ğŸ“– æ­£åœ¨åŠ è½½åˆå§‹å…³é”®è¯åˆ—è¡¨...")
            
            xhs_file = Path(XHS_DATA_FILE)
            if not xhs_file.exists():
                logger.error(f"æ–‡ä»¶ä¸å­˜åœ¨ï¼š{XHS_DATA_FILE}")
                print(f"âŒ æ‰¾ä¸åˆ°æ–‡ä»¶ï¼š{XHS_DATA_FILE}")
                return []
            
            with open(xhs_file, 'r', encoding='utf-8') as f:
                xhs_data = json.load(f)
            
            # è½¬æ¢æ•°æ®æ ¼å¼ï¼šä» {keyword: {çƒ­åº¦: value}} è½¬ä¸º [{word: keyword, heat: value}, ...]
            keywords_list = [
                {
                    'word': keyword,
                    'heat': data.get('çƒ­åº¦', 0)
                }
                for keyword, data in xhs_data.items()
            ]
            
            if not keywords_list:
                logger.warning("xhs_data.json ä¸­æ²¡æœ‰æœ‰æ•ˆæ•°æ®")
                print("âŒ xhs_data.json ä¸­æ²¡æœ‰æœ‰æ•ˆæ•°æ®")
                return []
            
            print(f"âœ“ å·²åŠ è½½ {len(keywords_list)} ä¸ªåˆå§‹å…³é”®è¯")
            
            # æ­¥éª¤2ï¼šä½¿ç”¨ Playwright çˆ¬è™«è·å–çƒ­æœæ•°æ®
            print("ğŸš€ å¯åŠ¨ Playwright çˆ¬è™«è·å–çƒ­æœæ•°æ®...")
            
            # æå–å…³é”®è¯æ–‡æœ¬åˆ—è¡¨ç”¨äºçˆ¬è™«
            keyword_texts = [item['word'] for item in keywords_list[:top_n]]
            
            try:
                # è°ƒç”¨ Playwright çˆ¬è™«
                trends_data = get_xhs_trends(keyword_texts)
                
                # åˆå¹¶ç»“æœï¼šä½¿ç”¨çˆ¬è™«è·å–çš„çƒ­æœæ•°æ®ï¼Œå¦‚æœçˆ¬è™«å¤±è´¥åˆ™ä½¿ç”¨æœ¬åœ°æ•°æ®
                result_trends = []
                for item in keywords_list[:top_n]:
                    keyword = item['word']
                    if keyword in trends_data:
                        # ä½¿ç”¨çˆ¬è™«æ•°æ®
                        result_trends.append({
                            'word': keyword,
                            'heat': trends_data[keyword].get('trend_score', item['heat']),
                            'note_count': trends_data[keyword].get('count', 0),
                            'source': 'crawler'
                        })
                    else:
                        # é™çº§ä½¿ç”¨æœ¬åœ°æ•°æ®
                        result_trends.append({
                            'word': keyword,
                            'heat': item['heat'],
                            'note_count': 0,
                            'source': 'local'
                        })
                
                print(f"âœ“ æˆåŠŸè·å– {len(result_trends)} ä¸ªçƒ­æœè¯æ¡")
                logger.info(f"è·å–çƒ­æœè¯æ¡æˆåŠŸï¼š{len(result_trends)} ä¸ª")
                
                return result_trends
            
            except ImportError as e:
                # Playwright æœªå®‰è£…ï¼Œä½¿ç”¨æœ¬åœ°æ•°æ®
                logger.warning(f"Playwright ä¸å¯ç”¨ï¼Œä½¿ç”¨æœ¬åœ°æ•°æ®ï¼š{e}")
                print(f"âš ï¸  Playwright ä¸å¯ç”¨ï¼Œä½¿ç”¨æœ¬åœ°ç¼“å­˜æ•°æ®")
                print(f"   è¯·è¿è¡Œï¼špip install playwright playwright-stealth")
                
                return keywords_list[:top_n]
        
        except Exception as e:
            logger.error(f"è·å–çƒ­æœè¯æ¡å¤±è´¥ï¼š{e}", exc_info=True)
            print(f"âŒ è·å–çƒ­æœè¯æ¡å¤±è´¥ï¼š{e}")
            return []
    
    def _analyze_keywords(self, keywords: List[Dict]) -> List[Dict]:
        """
        åˆ†æå…³é”®è¯çš„è“æµ·æŒ‡æ•°
        
        Args:
            keywords: çƒ­æœè¯æ¡åˆ—è¡¨
            
        Returns:
            åˆ†æç»“æœåˆ—è¡¨
        """
        results = []
        total = len(keywords)
        
        for idx, keyword_item in enumerate(keywords, 1):
            keyword = keyword_item.get('word', '')
            xhs_heat = keyword_item.get('heat', 0)
            
            if not keyword:
                continue
            
            print(f"\n[{idx}/{total}] æ­£åœ¨åˆ†æï¼š{keyword}")
            
            try:
                # æŸ¥è¯¢é—²é±¼æ•°æ®ï¼ˆéœ€è¦ä¼ é€’åˆ—è¡¨ï¼‰
                fish_info = get_fish_data([keyword])
                
                # è®¡ç®—è“æµ·æŒ‡æ•°
                index, analysis = BlueOceanAnalyzer.calculate_detailed_index(
                    xhs_data={'word': keyword, 'heat': xhs_heat},
                    fish_data=fish_info
                )
                
                results.append(analysis)
                
                # å¼ºåˆ¶å†·å´ï¼ˆé˜²æ­¢IPå°ç¦ï¼‰
                wait_time = random.uniform(*DELAY_BETWEEN_REQUESTS)
                print(f"â³ å†·å´ {wait_time:.1f} ç§’...")
                time.sleep(wait_time)
            
            except ImportError as e:
                # Playwright æœªå®‰è£…
                logger.warning(f"Playwright ä¸å¯ç”¨ï¼Œè·³è¿‡å…³é”®è¯ '{keyword}'ï¼š{e}")
                print(f"âš ï¸  Playwright ä¸å¯ç”¨ï¼Œä½¿ç”¨æœ¬åœ°æ•°æ®åˆ†æ")
                
                # å°è¯•ä»æœ¬åœ°æ•°æ®ä¸­è·å–é—²é±¼æ•°æ®
                try:
                    fish_file = Path('fish_data.json')
                    if fish_file.exists():
                        with open(fish_file, 'r', encoding='utf-8') as f:
                            fish_data_dict = json.load(f)
                        
                        fish_info = fish_data_dict.get(keyword, {
                            'å•†å“æ•°': 0,
                            'æƒ³è¦äººæ•°': 0
                        })
                        
                        index, analysis = BlueOceanAnalyzer.calculate_detailed_index(
                            xhs_data={'word': keyword, 'heat': xhs_heat},
                            fish_data=fish_info
                        )
                        results.append(analysis)
                except Exception as local_e:
                    logger.warning(f"ä½¿ç”¨æœ¬åœ°æ•°æ®åˆ†æå¤±è´¥ï¼š{local_e}")
                    continue
            
            except Exception as e:
                logger.warning(f"åˆ†æè¯æ¡ '{keyword}' å¤±è´¥ï¼š{e}")
                continue
        
        return results
    
    def _print_result(self, rank: int, result: Dict) -> None:
        """
        æ‰“å°å•ä¸ªåˆ†æç»“æœ
        
        Args:
            rank: æ’å
            result: åˆ†æç»“æœ
        """
        print(f"\nç¬¬ {rank} åï¼š{result['è¯æ¡']}")
        print(f"  ğŸ”¥ è“æµ·æŒ‡æ•°ï¼š{result['è“æµ·æŒ‡æ•°']} {result['è¯„çº§']}")
        print(f"  ğŸ“ˆ å°çº¢ä¹¦çƒ­åº¦ï¼š{result['å°çº¢ä¹¦çƒ­åº¦']:,.0f} {result['çƒ­åº¦è¯„ä¼°']}")
        print(f"  ğŸ›ï¸ ç«äº‰å¯¹æ‰‹ï¼š{result['é—²é±¼å•†å“æ•°']} {result['ç«äº‰åº¦è¯„ä¼°']}")
        print(f"  â¤ï¸ å¹³å‡æƒ³è¦æ•°ï¼š{result['å¹³å‡æƒ³è¦æ•°']:.1f} äºº")
    
    def _push_results(self, results: List[Dict]) -> None:
        """
        æ¨é€ç»“æœåˆ°ä¼ä¸šå¾®ä¿¡
        
        Args:
            results: è¦æ¨é€çš„ç»“æœåˆ—è¡¨
        """
        if not self.pusher or not results:
            return
        
        success_count = 0
        
        for result in results:
            success = self.pusher.push_to_wecom(
                keyword=result['è¯æ¡'],
                score=result['è“æµ·æŒ‡æ•°'],
                fish_count=result['é—²é±¼å•†å“æ•°'],
                avg_wants=result['å¹³å‡æƒ³è¦æ•°'],
                xhs_heat=int(result['å°çº¢ä¹¦çƒ­åº¦'])
            )
            
            if success:
                success_count += 1
                self.push_records.append({
                    'keyword': result['è¯æ¡'],
                    'timestamp': datetime.now().isoformat()
                })
            
            # æ¨é€ä¹‹é—´çš„é—´éš”
            time.sleep(2)
        
        print(f"âœ“ æ¨é€å®Œæˆï¼š{success_count}/{len(results)} æˆåŠŸ")
    
    def _save_report(self, results: List[Dict]) -> None:
        """
        ä¿å­˜åˆ†ææŠ¥å‘Š
        
        Args:
            results: åˆ†æç»“æœåˆ—è¡¨
        """
        report = {
            'timestamp': datetime.now().isoformat(),
            'total_analyzed': len(self.results),
            'top_results': results,
            'push_records': self.push_records,
            'config': {
                'min_potential_score': MIN_POTENTIAL_SCORE,
                'max_competition': MAX_COMPETITION
            }
        }
        
        try:
            with open(REPORT_FILE, 'w', encoding='utf-8') as f:
                json.dump(report, f, ensure_ascii=False, indent=2)
            logger.info(f"æŠ¥å‘Šå·²ä¿å­˜åˆ° {REPORT_FILE}")
            print(f"âœ“ æŠ¥å‘Šå·²ä¿å­˜åˆ°ï¼š{REPORT_FILE}")
        except Exception as e:
            logger.error(f"ä¿å­˜æŠ¥å‘Šå¤±è´¥ï¼š{e}")


def main():
    """ä¸»ç¨‹åºå…¥å£"""
    
    # åˆ›å»ºå¼•æ“å®ä¾‹
    engine = NicheHunterEngine()
    
    # æ‰§è¡Œä»»åŠ¡
    result = engine.run_mission(
        top_trends_n=15,      # æŠ“å–å‰15ä¸ªçƒ­æœ
        top_results_n=5,      # è¿”å›å‰5ä¸ªæœ€ä½³èµ›é“
        enable_push=ENABLE_WECOM_PUSH  # æ˜¯å¦æ¨é€åˆ°ä¼ä¸šå¾®ä¿¡
    )
    
    return result


if __name__ == '__main__':
    main()
